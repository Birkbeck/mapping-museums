---
title: "Mapping Museums: Geodemo analysis (Andrea Ballatore)"
output:
  html_document:
    self_contained: no
  pdf_document: default
---

<style>
pre:not([class]) {
    color: white;
    background-color: #272822;
}
</style>

# Setup

```{r setup}
source("mm_setup.R")

# load datasets
museums_bg = readRDS('../datasets/museums/museums_bg_sdf.rds')
stopifnot( nrow(museums_bg) == ALL_MUSEUMS_N )

OUTFOLD = "../plots/geodemo_analysis/"

analy_year = 2017
museums2017sdf = FUN_get_museums_open_in_a_year(museums_bg, analy_year)

nrow(museums2017sdf)
# write a note
write_file( paste0('Museums open in 2017: ',nrow(museums2017sdf)), 
            paste0(OUTFOLD,'museums_2017_stats.txt'))

gss_lib = readRDS("../datasets/uk_datasets/gss_lib.rds")

# duplicated in spatial_datasets.Rmd
find_gss_in_lib <- function(x){
  x = trimws(x)
  results = subset( gss_lib, gss_lib$GSS %in% x )
  notresults = x[!x %in% gss_lib$GSS]
  if (length(notresults)>0){
    #print(notresults)
    results = rbind(results, data.frame(GSS=notresults, FILE=NA) )
  }
  results$GSS = as.factor(as.character(results$GSS))
  results$FILE = as.factor(as.character(results$FILE))
  stopifnot(nrow(results)>=length(x))
  return(results)
}
```

# GeographyMuseumsUK paper

Analysis for paper GeographyMuseumsUK

## Prep data

https://mgimond.github.io/Spatial/point-pattern-analysis-in-r.html

special_type
- Small, independent museums 
- National
- Medium and large local authority museums


```{r}
stopifnot(nrow(museums2017sdf)==3262)
outfolder = "../plots/geodemo_analysis/distribution/"
FUN_clean_folder(outfolder)

stopifnot( nrow(uk_countries_reg_2011_simpl_bg)>0 )

museums2017uksdf = subset( museums2017sdf, !is.na(museums2017sdf$region_gss))
stopifnot(nrow(museums2017uksdf)==3225)

museumBboxBg <- bbox(museums2017uksdf)

gen_density_map = function(sdf, basesdf, bbox, outfolder, fout, mus_col, border_col, shape_col){

  attribution = tm_credits(get_plot_subtitle(paste0(outfolder,fout)), position = c("center","bottom"),alpha=.5)
  layout = tm_layout(frame=F,
      panel.label.size = 1.0, panel.label.color = 'black',
      panel.label.bg.color = NA, panel.label.height = 1.0)

    # full shapes
  m <- tmap::tm_shape(basesdf, simplify = .5, bbox = bbox) +
    #tm_polygons(col='gray85', border.col = 'white', lwd=2) +
    tm_borders(col = border_col, lwd = 1.5, alpha = 1) +
    tmap::tm_shape(sdf) + tmap::tm_symbols( col=mus_col, size=.2, alpha = .3, border.lwd = NA ) +
    #tm_shape(get_cities_for_labels(80000)) + # load cities
    #tm_text("name", col = "gray", size = .2, alpha = .7, auto.placement = F) + # city labels
    tm_legend(scale=0.45,position=c("right","top"), title=tit) + #, bg.color = "white", bg.alpha=.2,
    attribution + layout + tm_scale_bar(c(0,50,100))
    #, attr.outside = TRUE, title="PINUZZU",
              #outer.margins=c(.1,0,.0,0),title.position = c("center","bottom"))

  # add London inset
  sdf_London = sdf[ sdf$region_gss=='E12000007', ]
  london_base_sdf = basesdf[basesdf$NAME =='London', ]
  london_bbox = bbox(london_base_sdf)
  #stopifnot(nrow(sdf_London)==1)
  m_London <- tmap::tm_shape(london_base_sdf, simplify = .5, bbox = london_bbox) +
    #tm_polygons(col='gray85', border.col = 'white', lwd=2) +
    tm_borders(col = border_col, lwd = 1.5, alpha = 1) +
    tmap::tm_shape(sdf_London) + #tm_fill(var_col, breaks = brk, palette=col_palette,
    #border.alpha=0, auto.palette.mapping = T, title = NA, legend.show = F) +
    tmap::tm_symbols( col=mus_col, size=.2, alpha = .3, border.lwd = NA ) +
    tm_layout( frame = T, frame.lwd = 1 )

  vp_London <- viewport(x = 0.8, y = 0.58, width = 0.34, height = 0.34)
  
  tmap_mode("plot")
  m
  print(m_London, vp = vp_London)
  
  #save_tmap(m, paste0(outfolder, fout,'.png'), width = 4, height = 6)
  print(paste0('Maps in ',outfolder,fout))
  save_tmap(m, paste0(outfolder, fout,'.pdf'), width = 4, height = 6, 
            insets_tm = list(m_London), insets_vp = list(vp_London))
  #save_tmap(dot_map,paste0(outfolder,fout,'.png'))
  #save_tmap(dot_map,paste0(outfolder,fout,'.pdf'))
}

# uk_countries_reg_2011_bg
# uk_countries_reg_2011
# uk_countries_reg_2011_simpl_bg
gen_density_map(museums2017uksdf, uk_countries_reg_2011_bg, bbox=museumBboxBg, mus_col='steelblue3', 
                border_col='gray55', outfolder=outfolder,
                shape_col=NA, fout='museums_2017_distrib' )


summary(museums2017uksdf$special_type)
```

## Desc spatial stats

https://mgimond.github.io/Spatial/point-pattern-analysis-in-r.html

Autocorrelation measure (I) positive -> scale is bigger (ii) negative -> scale of the process is smaller

```{r museums_autocorr, eval=T}
stopifnot(nrow(museums2017uksdf)==3225)

sdf = museums2017uksdf

## plot sample data
if (F){
  #plot(sdf, xlab="", ylab="", asp=1, axes=FALSE, main="Activities Data (aspace)", type="n")
  ## SDD example
  #calc_sdd(id=1, filename="SDD_Output.txt", centre.xy=NULL, calccentre=TRUE, 
  #weighted=FALSE, weights=NULL, points=sdf@coords, verbose=FALSE)
  
  #plot_sdd(plotnew=FALSE, plotcentre=FALSE, centre.col="red", centre.pch="1", sdd.col="red",sdd.lwd=1,titletxt="", plotpoints=TRUE,points.col="black")
  
  # Label the centroid, explicitly using the hidden r.SDD object that was used in plot_sde
  #text(r.SDD$CENTRE.x, r.SDD$CENTRE.y, "+", col="red")
}

# descriptive spatial statistics
desc_spatial_stats = function(sdf){
  fn = paste0(outfolder,'museums_spatial_stats.pdf')
  print('desc_spatial_stats')
  print(nrow(sdf))
  print(fn)
  pdf(fn)
  
  pp  <- as(sdf, "ppp")

  # F - empty space function
  # the nearest neighbor distance test (sometimes called the G-function)
  f = spatstat::Fest(pp)
  plot(f)
    
  # G
  # the nearest neighbor distance test (sometimes called the G-function)
  g = spatstat::Gest(pp)
  plot(g)
  
  # K function
  # iso - Ripley isotropic correction estimate of K(r)
  # theo - theoretical Poisson K(r)
  k <- spatstat::Kest(pp, correction="Ripley")
  plot(k, xlab="d (m)", ylab="K(d)")
  
  plot(envelope(pp, Kest, nsim = 99, correction = "border"))
  
  # L function
  L <- spatstat::Lest(pp, correction="Ripley")
  plot(L, xlab="d (m)", ylab="K(d)")
  rm(k,L)
  
  
  # average nearest neighbor (ANN)
  ANN <- apply(nndist(sdf@coords, k=1:50),2,FUN=mean)
  plot(ANN ~ eval(1:50), type="b", main=NULL, las=1)
  
  ann.p <- mean(nndist(sdf@coords, k=1))
  ann.p # 3029.839 = 3.02 km
  
  # MONTE CARLO
  #n     <- 599L               # Number of simulations
  #ann.r <- vector(length = n) # Create an empty object to be used to store simulated ANN values
  #for (i in 1:n){
  #  rand.p   <- rpoint(n=pp$n, win=ma.km)  # Generate random point locations
  #  ann.r[i] <- mean(nndist(rand.p, k=1))  # Tally the ANN values
  #}
  
  dev.off()
}

# this shows that there is some clustering
# 3.02 km mean NN distance
desc_spatial_stats(sdf)

rm(sdf)
```

## Museums vs pop tables with z scores

Some custom charts for the article

```{r}
stopifnot(nrow(museums2017uksdf)==3225)
sdf = museums2017uksdf

plot_mus2017_region_vs_attr_z_scores = function(df, fout, label_sz, w, h){
  print(paste("plot_mus2017_region_vs_attr_z_scores",fout))
  row.names(df) = as.character(df$region)
  df$region = NULL
  zdf = as.data.frame(round(scale(df),1))
  row.names(zdf) = row.names(df)
  zdf$region = row.names(zdf)
  df$region = row.names(df)
  fn0 = paste0(OUTFOLD,fout)
  write_csv(zdf, paste0(fn0,"-matrix_summary.csv"))
  palette="PuBuGn"
  palette="RdYlBu"
  
  fn3 = paste0(fn0,"-matrix_summary_tiles_z.pdf")
  #df = 
  ddf = melt(zdf,id.vars=c("region"))
  ddf_label = melt(df,id.vars=c("region"))
  ddf$variable = gsub("_"," ",ddf$variable )
  ddf$label = as.character(ddf_label$value)
  ddf$label = gsub("^0$",'-',ddf$label)
  limit <- max(abs(ddf$value)) * c(-1, 1)
  
  ddf$variable = as.factor(as.character(ddf$variable))
  p = ggplot(ddf, aes(x=variable, y=reorder(region, desc(region)), fill=value, label=label)) + 
      #ylim(-10, ymax) + 
      #geom_ribbon(aes(x=r, ymax = hi-r, ymin = lo-r), alpha = 0.2, fill = "gray") +
      #geom_line(aes(linetype=gpoi_type, color=gpoi_type)) +
      geom_tile() + 
      geom_text(size = label_sz, color="grey50") +   
      #scale_color_manual(ddf$label_color)+
      #geom_smooth(aes(linetype=lit_type, color=lit_type), size=sz, se = F, n = 200) + 
      theme_light() +
      theme(axis.text.x = element_text(angle = 35, hjust = 1)) +
      scale_fill_distiller(palette=palette, direction = 1, limit=limit) + # PuBuGn
      #scale_fill_distiller(palette = "Spectral")
      #geom_line(aes(x=r, y=0), color="black", size=.3) +  # random baseline at y = 0
      geom_vline(aes(xintercept=seq(1,nrow(ddf))+.5),colour="grey50",size=.4) +
      ggtitle(paste0("TEST"), subtitle=fn3)
  ggsave(fn3, p, width=w, height=h)
  
  ddf
  
  rm(ddf)
}

# ------------------------------------------------------------------
# counts vs counts per 100k people (size + subj matter + gov)
# ------------------------------------------------------------------

pop = as.data.frame(read_csv('../plots/geodemo_analysis/population/mus2017_region_name_vs_pop17_table.csv'))

# plot z scores of regions to show variation by region
df = as.data.table(read.csv("../datasets/museums/mus2017_region_vs_size_gov-counts-v1.csv"))
df$unknown_sz = NULL
df$unknown_gov = NULL
plot_mus2017_region_vs_attr_z_scores(df, 'distribution/mus17_size_gov_by_region', 2.4, 5, 4)

# subject matter counts
#df$small_z = round(scale(df$small),1)
df = as.data.table(read.csv("../datasets/museums/mus2017_region_vs_subj-counts-v1.csv"))
plot_mus2017_region_vs_attr_z_scores(df, 'distribution/mus17_subj_by_region', 2, 7.5, 4)

# subject matter counts per 100k
df[11,"region"]="Scotland"
df[12,"region"]="Wales"
df[10,"region"]="Northern Ireland"
df = as.data.frame(merge(df, pop[,c("region","pop_2017")]))
for (v in names(df)){
  if (v %in% c("region","pop_2017")) next()
  print(df[,v])
  #df[,paste0(v,"_100k")]
  df[,v] = round(df[,v] / (df$pop_2017/100000),2)
}
df$pop_2017 = NULL
row.names(df)=df$region
df["Scotland","region"]="z_Scotland"
df["Wales","region"]="z_Wales"
df["Northern Ireland","region"]="z_Northern Ireland"

plot_mus2017_region_vs_attr_z_scores(df, 'distribution/mus17_subj100k_by_region', 2, 7.5, 4)


nrow(sdf)

# size
szdf = as.data.frame.matrix(table(sdf@data[,c("region_name","size")]))
szdf$region = row.names(szdf)
govdf = as.data.frame.matrix(table(sdf@data[,c("region_name","governance_simpl")]))
govdf$region = row.names(govdf)

df = merge(szdf, pop, by.x="region", by.y="region")
df = merge(df, govdf, by.x="region", by.y="region")

df = subset(df, df$region!='England')

df$unknown_gov = NULL
df$unknown_sz = NULL

vars = c("small","medium","large","huge","government","independent","university")
for (v in vars){
  df[,paste0(v,"_100k")] = round(df[,v] / (df$pop_2017/100000),1)
}

row.names(df) = df$region

df["Scotland","region"]="z_Scotland"
df["Wales","region"]="z_Wales"
df["Northern Ireland","region"]="z_Northern Ireland"

names(df)

vars1 = c("region","small","small_100k","medium","medium_100k","large","large_100k","huge","huge_100k",
          "government","government_100k","independent","independent_100k","university","university_100k")
sz_df = df[,vars1]
names(sz_df) = c("region","s1_small","s1_small_100k","s2_medium","s2_medium_100k",
                 "s3_large","s3_large_100k","s4_huge","s4_huge_100k",
                 "z1_government","z1_government_100k","z2_independent","z2_independent_100k",
                 "z3_university","z3_university_100k")
plot_mus2017_region_vs_attr_z_scores(sz_df, 'distribution/mus17_size_by_region', 2, 5.5, 4)

# ------------------------------------------------------------------
# counts vs counts per 100k people (special types)
# ------------------------------------------------------------------
stdf = as.data.frame.matrix(table(sdf@data[,c("region_name","special_type")]))
stdf$region = row.names(stdf)
stdf = merge(stdf, pop, by.x="region", by.y="region")
df = subset(stdf, stdf$region!='England')
row.names(df) = df$region
df["Scotland","region"]="z_Scotland"
df["Wales","region"]="z_Wales"
df["Northern Ireland","region"]="z_Northern Ireland"

vars = c("local_auth","national","sm_indep")
for (v in vars){
  df[,paste0(v,"_100k")] = round(df[,v] / (df$pop_2017/100000),2)
}

vars1 = c("region","sm_indep","sm_indep_100k","local_auth","local_auth_100k","national","national_100k")
df = df[,vars1]
plot_mus2017_region_vs_attr_z_scores(df, 'distribution/mus17_specialtype_by_region', 2, 4.5, 4)


rm(df,szdf,govdf)
rm(sdf)
```

## Kernels on points

(Not working well)

```{r}

sdf = museums2017uksdf
bins = 15
size = .001

generate_kde_map = function( sdf, fn, size, bins ){
  print(paste0('generate_kde_map',fn))
  #sdf@data$lon = sdf@coords['longitude']
  #sdf@data$lat = sdf@coords['latitude']
  
  p = ggplot(as.data.frame(sdf@coords), aes(x = longitude, y = latitude)) + 
    coord_equal() + 
    xlab('Longitude') + 
    ylab('Latitude') + 
    #stat_density2d(aes(fill = ..level..), alpha = .5,
    stat_density2d(aes(fill = stat(level)), contour = T, alpha = .8,
                   geom = "polygon", size = size, bins = bins) + 
    scale_fill_viridis_c() + 
    theme() # legend.position = 'none'
  
  ggsave(fn, p, width = 6, height = 8)
}

generate_kde_map(sdf, paste0(outfolder,'kde_map_s',size,'_b',bins,'.pdf'), size, bins)

rm(sdf)

```

## Reapportion from grid to hex

```{r}

# gen hex 10km grid 
popgrid = load_uk_dataset(paste0('uk_census_2011/uk_population_5kmgrid-2011-sdf.rds'))
hexgrid = load_uk_dataset(paste0('uk_hex_grids/uk_hex_grid_2011-10km.rds'))
hexgridpop = FUN_apportion_geographies(popgrid, hexgrid, 'pop2011')

summary(hexgridpop$pop2011); sum(hexgridpop$pop2011)
summary(popgrid$pop2011); sum(popgrid$pop2011)
saveRDS(hexgridpop, paste0(outfolder,'uk_pop_hex_grid-10km.rds'))

# gen hex 5km grid
popgrid = load_uk_dataset(paste0('uk_census_2011/uk_population_2kmgrid-2011-sdf.rds'))
hexgrid = load_uk_dataset(paste0('uk_hex_grids/uk_hex_grid_2011-5km.rds'))
hexgridpop = FUN_apportion_geographies(popgrid, hexgrid, 'pop2011')

summary(hexgridpop$pop2011); sum(hexgridpop$pop2011)
summary(popgrid$pop2011); sum(popgrid$pop2011)
saveRDS(hexgridpop, paste0(outfolder,'uk_pop_hex_grid-5km.rds'))

#write_geojson(spTransform(hexgridpop,ll_crs),'../tmp/new_geog.geojson','new_geo')
#write_geojson(spTransform(popgrid,ll_crs),'../tmp/old_geog.geojson','old_geo')

rm(popgrid,hexgrid,hexgridpop)

```

## Pop grids

```{r}
outfolder = "../plots/geodemo_analysis/distribution/"

msdf = museums2017uksdf
POP_SCALE = 100*1000

popMuseumStat = function(museums_sdf, popsdf){
  print(paste('popMuseumStat:',nrow(museums_sdf),nrow(popsdf),'POP_SCALE =',POP_SCALE))
  mgrid = FUN_calc_grid_counts(msdf, popsdf, checkSum = F)
  mgrid$nmus = mgrid$VAR
  mgrid$VAR = NULL
  print(nrow(mgrid))
  mgrid$nmus_ppl = round(mgrid$nmus / (mgrid$pop2011/POP_SCALE),4)
  mgrid$nmus_ppl[is.nan(mgrid$nmus_ppl)] = NA
  #print(summary(mgrid$nmus_ppl))
  print(summary(mgrid@data))
  print(paste("Sum nmus",nrow(museums_sdf)))
  print(paste("Sum nmus in grid",sum(mgrid$nmus)))
  
  print(summary(mgrid$nmus[mgrid$nmus>0]))
  print(summary(mgrid$nmus_ppl[mgrid$nmus_ppl>0]))
  print(paste('Zero pop cells:',round(length(mgrid$pop2011[mgrid$pop2011==0])/nrow(mgrid),2)))
  print(paste('Zero mus cells:',round(length(mgrid$nmus[mgrid$nmus==0])/nrow(mgrid),2)))
  return(mgrid)
}

# QUADRANTS (squares)
for (v in c(5,10)){ # 1,2,5,10 1,5,
  print(paste('Quadrants km',v,'-------------------------'))
  popsdf = load_uk_dataset(paste0('uk_census_2011/uk_population_',v,'kmgrid-2011-sdf.rds'))
  grid_sdf = popMuseumStat(msdf, popsdf)
  print(names(grid_sdf))
  fn = paste0(outfolder,'mus_pop_grid_',v,'km_sdf.rds')
  print(fn)
  saveRDS(grid_sdf,fn)
  
  # histograms not useful, extremely skewed distribution
  #grid_sdf@data$nmus_t = asinh(grid_sdf@data$nmus)
  #g = ggplot(grid_sdf@data, aes(x=nmus)) + geom_histogram()
  
  rm(popsdf)
}
rm(msdf)
  
  # [1] "Quadrants km 5 -------------------------"
  # [1] "popMuseumStat: 3225 9185 POP_SCALE = 1e+05"
  # [1] 9185
  #     pop2011            nmus          nmus_ppl       
  #  Min.   :     0   Min.   : 0.00   Min.   :    0.00  
  #  1st Qu.:   281   1st Qu.: 0.00   1st Qu.:    0.00  
  #  Median :  1126   Median : 0.00   Median :    0.00  
  #  Mean   :  6879   Mean   : 0.35   Mean   :   28.15  
  #  3rd Qu.:  4486   3rd Qu.: 0.00   3rd Qu.:    0.00  
  #  Max.   :342625   Max.   :74.00   Max.   :14285.71  
  #                                   NA's   :18        
  # [1] "Sum nmus 3225"
  # [1] "Sum nmus in grid 3215"
  #    Min. 1st Qu.  Median    Mean 3rd Qu.    Max. 
  #   1.000   1.000   1.000   1.667   2.000  74.000 
  #      Min.   1st Qu.    Median      Mean   3rd Qu.      Max.      NA's 
  #     0.429     7.254    21.570   133.761    66.979 14285.714        18 
  # [1] "Zero cells: 0.79"
  # [1] "../plots/geodemo_analysis/distribution/mus_pop_grid_5km_sdf.rds"
  # [1] "Quadrants km 10 -------------------------"
  # [1] "popMuseumStat: 3225 2730 POP_SCALE = 1e+05"
  # [1] 2730
  #     pop2011               nmus            nmus_ppl      
  #  Min.   :      0.0   Min.   :  0.000   Min.   :   0.00  
  #  1st Qu.:    790.5   1st Qu.:  0.000   1st Qu.:   0.00  
  #  Median :   4843.0   Median :  0.000   Median :   0.00  
  #  Mean   :  23144.6   Mean   :  1.181   Mean   :  33.90  
  #  3rd Qu.:  18375.0   3rd Qu.:  2.000   3rd Qu.:  11.36  
  #  Max.   :1104823.0   Max.   :117.000   Max.   :9090.91  
  #                                        NA's   :1        
  # [1] "Sum nmus 3225"
  # [1] "Sum nmus in grid 3223"
  #    Min. 1st Qu.  Median    Mean 3rd Qu.    Max. 
  #   1.000   1.000   2.000   2.477   3.000 117.000 
  #     Min.  1st Qu.   Median     Mean  3rd Qu.     Max.     NA's 
  #    0.402    4.965   12.268   71.117   30.506 9090.909        1 
  # [1] "Zero cells: 0.52"
  # [1] "../plots/geodemo_analysis/distribution/mus_pop_grid_10km_sdf.rds"

# MORAN'S I
calcAllMoransI = function(filen, cell_sz){
  sdf = readRDS(paste0(outfolder,filen))
  midf = data.frame()
  for (neiK in c(4,8,23)){
  for (vv in names(sdf)){
    mi = FUN_globalMoransI(sdf, vv, neiK, removeMissing = T)
    midf = rbind( midf, data.frame( N = nrow(sdf), 
          FILE = filen,
          CELL_SZ_KM = cell_sz, VARIABLE=vv, NEI_K = neiK, 
          MI = round( mi$estimate["Moran I statistic"], 3), VARIANCE = mi$estimate["Variance"],
          PVAL = mi$p.value, ALT=mi$alternative, 
          MI_STDEVIATE = mi$statistic ) )
  }}
  return(midf)
}

morani_df = rbind( 
  calcAllMoransI( 'mus_pop_grid_5km_sdf.rds', 5),
  calcAllMoransI( 'mus_pop_grid_10km_sdf.rds', 10 ) 
)
View(morani_df)
write_xlsx(morani_df, paste0(outfolder,"museums_moran_i.xlsx"))
```

### Plot hex grids

For paper "geography of UK museums" (2020) 

```{r}

plot_hex_grid = function( grid_sdf, bounds_sdf, fn, bin_n=6, binning='kmeans', 
                          col_palette='', scalebargaps = c(0,50,100), removeZeros = T, 
                          breaks=NA, title=NA){
  grid_sdfx = grid_sdf
  if(removeZeros){
    grid_sdfx = subset( grid_sdf, grid_sdf$VAR > 0 )
  }
  
  if (is.na(breaks)){
    brks = FUN_bin_var(grid_sdfx$VAR, binning, bin_n, isolateZeros = T, roundInt =  T)
  } else {
    brks = breaks
  }
  print(brks)
  p <- 
    tmap::tm_shape(grid_sdf) + tm_fill('white') +
    # bbox = bbox, , simplify = .25
    tmap::tm_shape(grid_sdfx) + tm_fill('VAR', breaks = brks, palette=col_palette, # border.alpha=.5, 
        #auto.palette.mapping = T, 
        title = '', alpha=1) + # tm_borders(col = 'white', lwd = .2, alpha = 1) +
    #tm_scale_bar(width=0.1, position=c("right","bottom")) + 
    tmap::tm_shape(bounds_sdf) + tm_borders(col = 'white', lwd = 1.7, alpha = .5) +
    tmap::tm_shape(bounds_sdf) + tm_borders(col = 'gray60', lwd = 1, alpha = 1) +
    tm_legend(scale=1.3) + #attribution +
    tm_layout(title=title, frame=FALSE, legend.title.size=.6, legend.text.size=.4, 
              legend.position = c("left","top")) +
    tm_xlab('', size = .3) + tm_scale_bar(scalebargaps, lwd=.5, text.size = .4) # , text.color='gray'
  print(fn)
  
  tmap::tmap_save(p, fn)
}

col_palettes = c("YlGnBu") #, "PuBu", "YlOrRd" ) #"YlGnBu", "PuBu"

print(outfolder)

# ----------------------------------------
# All museums - hex grid
# ----------------------------------------
#region_bounds_sdf = readOGR(dsn = "../../049-SpatialDatasets/data/uk_data/uk_countries_and_eng_regions_2011-manual_simpl.geojson")

region_bounds_sdf = readOGR(dsn = "../../049-SpatialDatasets/data/uk_data/uk_countries_and_eng_regions_2011-manual_simpl.topojson")

for (v in c('100km','200km')) # 
for (cpalette in col_palettes){ #
  msdf = museums2017uksdf
  #uk_grid = load_uk_dataset(paste0('uk_hex_grids/uk_hex_grid_2011-',v,'.rds'))
  #uk_grid_bounds = load_uk_dataset(paste0('uk_hex_grids/uk_hex_grid_2011-',v,'_bounds.rds'))
  uk_grid = load_uk_dataset(paste0('uk_hex_grids/uk_hex_grid_2011-area',v,'.rds'))
  uk_grid_bounds = load_uk_dataset(paste0('uk_hex_grids/uk_hex_grid_2011-area',v,'_bounds.rds'))
  
  mgrid = FUN_calc_grid_counts(msdf,uk_grid)
  
  # hotspot analysis
  #mgrid = FUN_localGiStar(mgrid, var_name = "VAR")
  #FUN_gen_autocorrel_maps(mgrid, "VAR", outfolder)
  
  #write_geojson( spTransform(mgrid,ll_crs), paste0(outfolder,'museums_hex_grid-area',v,'.geojson'), 'museums_hex')
  summary(mgrid$VAR)
  plot_hex_grid(mgrid, region_bounds_sdf,  #uk_grid_bounds,
                paste0(outfolder,'museums_hex_grid-',v,'-',cpalette,'.pdf'),
                col_palette=cpalette) #, bounds_sdf=region_bounds_sdf)
}

# LONDON HEX grids
for (v in c('2000m')) # '5000m'
for (cpalette in col_palettes){ # '5km',
  msdf = museums2017uksdf
  uk_grid = load_uk_dataset(paste0('uk_hex_grids/london_hex_grid_2011-area',v,'.rds'))
  uk_grid_bounds = load_uk_dataset(paste0('uk_hex_grids/london_hex_grid_2011-area',v,'_bounds.rds'))
  mgrid = FUN_calc_grid_counts(msdf,uk_grid,checkSum=F)
  print(paste('London museums: ',sum(mgrid$VAR)))
  write_geojson( spTransform(mgrid,ll_crs), paste0(outfolder,'museums_hex_grid-london-',v,'.geojson'), 'museums_hex')
  summary(mgrid$VAR)
  plot_hex_grid(mgrid, uk_grid_bounds,
                paste0(outfolder,'museums_hex_grid-london-',v,'-',cpalette,'.pdf'),
                col_palette=cpalette,scalebargaps=c(0,5,10),bin_n = 5)
}

# ----------------------------------------
# 2017 museums - hex grid by attribute 
# ----------------------------------------

gen_hex_plot_grouped_by_var = function(msdf, var){
  cpalette = "YlGnBu"
  print(paste("gen_hex_plot_grouped_by_var", var))
  vals = unique(msdf@data[,var])
  msdf$MYVAR = msdf@data[,var]
  grid_sz = '100km'
  
  #uk_grid = load_uk_dataset(paste0('uk_hex_grids/uk_hex_grid_2011-',v,'.rds'))
  #uk_grid_bounds = load_uk_dataset(paste0('uk_hex_grids/uk_hex_grid_2011-',v,'_bounds.rds'))
  uk_grid = load_uk_dataset(paste0('uk_hex_grids/uk_hex_grid_2011-area',grid_sz,'.rds'))
  uk_grid_bounds = load_uk_dataset(paste0('uk_hex_grids/uk_hex_grid_2011-area',grid_sz,'_bounds.rds'))
  print(nrow(uk_grid))
  for (val in vals){
    sdf = subset(msdf, msdf$MYVAR==val)
    print(paste(val,nrow(sdf)))
    mgrid = FUN_calc_grid_counts(sdf,uk_grid)
    breaks = c(0,1,2,4,8,16,32)
    plot_hex_grid(mgrid, region_bounds_sdf,
                paste0(outfolder,'museums_hex_grid-',grid_sz,'-',cpalette,'--',var,"-",val,'.pdf'), 
                col_palette=cpalette, breaks=breaks, title=val)
    write_geojson( spTransform(mgrid,ll_crs), 
                 paste0(outfolder,'museums_hex_grid-area',grid_sz,"-",var,"-",val,'.geojson'),
                 paste0('museums_hex-',var,'-',val))
  }
  
  # hotspot analysis
  #mgrid = FUN_localGiStar(mgrid, var_name = "VAR")
  #FUN_gen_autocorrel_maps(mgrid, "VAR", outfolder)
  
  
}

msdf = museums2017uksdf
gen_hex_plot_grouped_by_var(msdf, "size")
gen_hex_plot_grouped_by_var(msdf, "governance_simpl")
gen_hex_plot_grouped_by_var(msdf, "subject_matter_simpl_aggr")
gen_hex_plot_grouped_by_var(subset(msdf,!is.na(msdf$special_type)), "special_type")

View(p_summary_list(msdf$subject_matter_simpl,"2017 subject matter"))

# ----------------------------------------
# 2017 museums - hex grid by museum subject - dominant 
# ----------------------------------------

calc_dominant_category_hex = function(points_sdf, var, outfolder){
  grid_sz = "200km"
  uk_grid = load_uk_dataset(paste0('uk_hex_grids/uk_hex_grid_2011-area',grid_sz,'.rds'))
  uk_grid_bounds = load_uk_dataset(paste0('uk_hex_grids/uk_hex_grid_2011-area',grid_sz,'_bounds.rds'))
  points_sdf$VAR_TMP = points_sdf@data[,c(var)]

  # order factor elements alphabetically
  points_sdf$VAR_TMP = as.character(points_sdf$VAR_TMP)
  
  # get top category for each cell
  uk_grid$CELL_ID_TMP = seq(nrow(uk_grid))
  over_df = sp::over(points_sdf, spTransform(uk_grid, proj4string(points_sdf)))
  points_sdf = spCbind(points_sdf, over_df)
  
  df = FUN_subgroups(points_sdf@data[,c("CELL_ID_TMP","VAR_TMP")], "CELL_ID_TMP", function(d){
    dd = d[1,]
    #d$VAR_TMP
    #print(nrow(dd))
    data.frame(CELL_ID_TMP = dd$CELL_ID_TMP, 
               TOP_CAT = names(sort(table(d$VAR_TMP), decreasing=TRUE)[1]))
  })
  #View(df)
  View(as.data.frame(table(df$TOP_CAT)))
  
  gridc_sdf = merge(uk_grid, df, by='CELL_ID_TMP',all.x=T)
  #gridc_sdf$VAR[ is.na(gridc_sdf$VAR) ] = 0
  gridc_sdf$CELL_ID_TMP = NULL
  col_palette = "Pastel1" #"Pastel1" Accent
  gridc_sdf = subset(gridc_sdf, !is.na(gridc_sdf$TOP_CAT))
  # sort category
  gridc_sdf$TOP_CAT = factor(gridc_sdf$TOP_CAT, ordered=T, levels=sort(as.character(unique(gridc_sdf$TOP_CAT))))
  
  fn = paste0(outfolder,'museums_hex_grid-top_category-hex-',var,'.pdf')
  p <- 
    tmap::tm_shape(gridc_sdf) + #tm_fill('white') +
    #tmap::tm_shape(grid_sdfx) + # bbox = bbox, , simplify = .25
    tm_polygons('TOP_CAT', palette=col_palette, legend.hist = TRUE,
        #border.alpha=.5, 
        #auto.palette.mapping = T,
        lwd = .2,
        border.col = "white",
        title = '') + #+ tm_borders(col = 'white', lwd = .1, alpha = 1) +
    tmap::tm_shape(uk_grid_bounds) + tm_borders(col = 'gray', lwd = .8, alpha = 1) +
    #tm_scale_bar(width=0.1, position=c("right","bottom")) + 
    tm_legend(scale=2) + #attribution +
    tm_layout(frame=FALSE, legend.title.size=.6, legend.text.size=.4, legend.position = c("left","top"),
              legend.hist.height=.1, legend.hist.width=.2) +
    tm_xlab('', size = .3) + tm_scale_bar(c(0,50,100), lwd=.5, text.size = .4) # , text.color='gray'
  print(fn)

  tmap::tmap_save(p, fn)

  return(gridc_sdf)
}

sdf = calc_dominant_category_hex(museums2017uksdf, "size", outfolder)
sdf = calc_dominant_category_hex(museums2017uksdf, "governance_simpl", outfolder)

# remove some small categories for top category map
sdf = subset(museums2017uksdf, !(museums2017uksdf$subject_matter_simpl_aggr %in% 
      c("medicine_and_health","communications","services","other","mixed",
        "natural_world","utilities","food_and_drink","science_and_technology", "SMALL_SUBJECTS")))
#calc_dominant_category_hex(sdf, "subject_matter_simpl", outfolder)
sdf = calc_dominant_category_hex(sdf, "subject_matter_simpl_aggr", outfolder)
sdf = calc_dominant_category_hex(museums2017uksdf, "accreditation", outfolder)



```

## Point pattern analysis

For geography paper

```{r}
outf = paste0(outfolder, "point_pattern/")
print(outf)

max_dist_m = 100000  # max distance in L function

point_pattern_analysis_by_attr = function(sdf, attr){
  print(attr)
  reg_pp = as.ppp(sdf[,c(attr)])
  all_pp = reg_pp
  all_pp$marks = rep("all",all_pp$n)
  all_pp$marks = as.factor(all_pp$marks)
  
  #res <- spatstat::envelope(pp, spatstat::Lcross, correction = "Ripley", verbose = F)
  #summary(res)
  
  L_values_df = data.frame()
  pp = spatstat::superimpose(all_pp, reg_pp)
  pp$marks = as.factor(as.character(pp$marks))
  
  for(mark in unique(pp$marks)){
    print(mark)
    res <- spatstat::envelope(pp, spatstat::Lcross, correction = "Ripley", 
                              i = mark, j = mark, verbose = F)
    #res1 <- spatstat::envelope(subset(pp, marks==poi_type), spatstat::Lest, correction = "Ripley", verbose = F)
    L_values_df = rbind(L_values_df, data.frame(mark=mark, 
                                        r=round(res$r), obs=round(res$obs), 
                                        lo=round(res$lo), hi=round(res$hi)))
  }
  poifn = paste0(outf,"mus17_L_values_df-",attr,".rds")
  saveRDS(L_values_df, poifn) 
  
  # ----------------------------------------------------------------------------------------
  # plot L function lines
  # ----------------------------------------------------------------------------------------
  df = L_values_df
  
  df = df[df$r <= max_dist_m, ]  # filter radius
  summary(df)
  fn0 = paste0(outf,"mus17_L_values_df-lines-",attr,".pdf")
  print(fn0)
  
  p = ggplot(df, aes(x=r, y=obs-r, group=mark)) + 
    #ylim(-10, ymax) + 
    geom_ribbon(aes(x=r, ymax = hi-r, ymin = lo-r), alpha = 0.5, fill = "gray") +
    #geom_line(aes(linetype=poi_type, color=poi_type)) + 
    geom_smooth(aes(linetype=mark, color=mark), size=.5, se = F, n = 200) + 
    theme_light() +
    geom_line(aes(x=r, y=0), color="black", size=.3) +  # random baseline at y = 0
    ggtitle(paste0("L function"), subtitle=fn0)
  ggsave(fn0, p, width=6, height=5)
  # generate details
  p1 = p + facet_grid(. ~ mark)
  ggsave(paste0(fn0,"-details.pdf"), p1, width=35, height=4)
  
  # ---------------------------------------------------------------------------------------
  # Plot L summary
  # ---------------------------------------------------------------------------------------
  df = FUN_subgroups(L_values_df, c("mark"), function(dd){
    d = dd[1,]
    d$avg_L = round(mean(dd$obs))
    d$max_L = round(max(dd$obs))
    print(summary(dd$r))
    d[,c("mark","avg_L","max_L")]
  })
  #View(mat_df)
  df$avg_LZ = round(scale(df$avg_L),1)
  write_csv(df,paste0(fn0,"-summary.csv"))
  
  # ---------------------------------------------------------------------------------------
  # L function mark vs mark (types)
  # ---------------------------------------------------------------------------------------
  L_values_df = data.frame()
  #pp = spatstat::superimpose(all_pp, reg_pp)
  #pp$marks = as.factor(as.character(pp$marks))
  
  for(mark1 in unique(pp$marks))
    for(mark2 in unique(pp$marks)){
    print(paste(mark1, mark2))
    res <- spatstat::envelope(pp, spatstat::Lcross, correction = "Ripley", 
                              i = mark1, j = mark2, verbose = F)
    #res1 <- spatstat::envelope(subset(pp, marks==poi_type), spatstat::Lest, correction = "Ripley", verbose = F)
    L_values_df = rbind(L_values_df, data.frame(mark1=mark1, mark2=mark2,
                                      r=round(res$r),   obs=round(res$obs), 
                                      lo=round(res$lo), hi=round(res$hi)))
  }
  print(names(L_values_df))
  
  df = FUN_subgroups(L_values_df, c("mark1","mark2"), function(dd){
    d = dd[1,]
    print(d)
    d$avg_L = round(mean(dd$obs))
    d$sdev_L = round(sd(dd$obs),1)
    d$max_L = round(max(dd$obs))
    print(summary(dd$r))
    d[,c("mark1","mark2","avg_L","sdev_L","max_L")]
  })
  
  #View(mat_df)
  df$avg_LZ = -round(scale(df$avg_L),1)
  write_csv(df,paste0(fn0,"-matrix_summary.csv"))
  palette="PuBuGn"
  palette="RdYlBu"
  #palette="BuYlRd"
  
  fn3 = paste0(fn0,"-matrix_summary_tiles_z.pdf")
  p = ggplot(df, aes(x=mark1, y=mark2, fill=avg_LZ)) + 
      #ylim(-10, ymax) + 
      #geom_ribbon(aes(x=r, ymax = hi-r, ymin = lo-r), alpha = 0.2, fill = "gray") +
      #geom_line(aes(linetype=gpoi_type, color=gpoi_type)) +
      geom_tile() + 
      #geom_smooth(aes(linetype=lit_type, color=lit_type), size=sz, se = F, n = 200) + 
      theme_light() +
      theme(axis.text.x = element_text(angle = 35, hjust = 1)) +
      scale_fill_distiller(palette=palette, direction = 1) + # PuBuGn
      #scale_fill_distiller(palette = "Spectral")
      #geom_line(aes(x=r, y=0), color="black", size=.3) +  # random baseline at y = 0
      ggtitle(paste0("Mark vs Mark"), subtitle=fn3)
  ggsave(fn3, p, width=6.1, height=5.1)
  
  rm(df,p,p1,fn0)
}


stopifnot(nrow(museums2017uksdf)==3225)

cols = c("governance_simpl","accreditation","size","accreditation",
              "subject_matter_simpl_aggr",
              "subject_matter_simpl",
              "governance","region_name","country_name")

cols = c("subject_matter_simpl_aggr")

for (col in cols){
  df = museums2017uksdf
  if (col == "size"){
    df = subset(df, df$size %in% c("small","medium","large"))
  }
  if (col == "governance_simpl"){
    df = subset(df, !(df$governance_simpl %in% c("unknown_gov")))
    df$governance_simpl = as.factor(as.character(df$governance_simpl))
    print(unique(df$governance_simpl))
  }
  if (col == "special_type"){
    df = subset(df, !(is.na(df$special_type)))
    #df$governance_simpl = as.factor(as.character(df$governance_simpl))
    print(unique(df$special_type))
  }
  if (col == "subject_matter_simpl"){
    df = subset(df, !(df$subject_matter_simpl %in% c("other")))
    df$subject_matter_simpl = as.factor(as.character(df$subject_matter_simpl))
    print(unique(df$subject_matter_simpl))
  }
  if (col == "subject_matter_simpl_aggr"){
    df = subset(df, !(df$subject_matter_simpl_aggr %in% c("other",'SMALL_SUBJECTS')))
    df$subject_matter_simpl_aggr = as.factor(as.character(df$subject_matter_simpl_aggr))
    print(unique(df$subject_matter_simpl_aggr))
  }
  
  print(nrow(df))
  point_pattern_analysis_by_attr(df, col)
}

#View(df)
```

# Museums vs population
## Regional pop vs museums

Population at country/regional level by governance

data manually created in mus2017_region_name_vs_pop17.xlsx

```{r}
engl_regs = load_uk_dataset('eng_regions_2011-simp005.rds')
engl_regs = rmapshaper::ms_simplify(engl_regs, keep = .05)

stopifnot(nrow(uk_countries_reg_2011_simpl)>0)
stopifnot(nrow(engl_regs)>0)

gen_pop_regional_map = function( sdf, var_name, fn, tit ){
  print(paste('gen_pop_regional_map',var_name))
  m <- tmap::tm_shape(sdf) + # bbox = bbox, , simplify = .25
    tm_fill(var_name, n=5, style='equal', palette="YlOrRd",
          border.alpha=0, auto.palette.mapping = F, 
          title = tit) +
    #tm_scale_bar(width=0.1, position=c("right","bottom")) + 
    tm_legend(scale=0.95) + #attribution +
    tmap::tm_shape(sdf) + 
    tm_borders(col = 'white', lwd = .4, alpha = 1) +
    #tm_text('NAME') +
    tm_layout(frame=FALSE, legend.title.size=.6, legend.text.size=.4, legend.position = c("left","top")) +
    tm_xlab(fn, size = .3)
  save_tmap(m, fn, width = 3, height = 5)
  print(fn)
}

pop = read_csv('../plots/geodemo_analysis/population/mus2017_region_name_vs_pop17_table.csv')

popsdf = merge(uk_countries_reg_2011_simpl,pop,by.x='NAME',by.y='region')
pop = popsdf@data
names(popsdf)
popsdf$museums_per_100kpop = round(popsdf$museums_per_100kpop,1)
summary(popsdf$museums_per_100kpop)

# all museums 2017
fn = '../plots/geodemo_analysis/population/region_mus17_pop100k_map.pdf'
gen_pop_regional_map(popsdf, 'museums_per_100kpop', fn, 'Museums by 100,000 residents (2017)')

fn = '../plots/geodemo_analysis/population/region_mus17_pop100k_map_engl.pdf'
gen_pop_regional_map(
  subset( popsdf, !(popsdf$NAME %in% c('Northern Ireland','Scotland','Wales'))), 
  'museums_per_100kpop', fn, 'Museums by 100,000 residents (2017)')

# museums 2017 by governance
df = museums2017sdf@data

#df = subset( df, !(df$country_name %in% c('Northern Ireland','Scotland','Wales')))
gov_df = FUN_count_groups_by_vars(df,c('governance_simpl','region_gss'))
gov_df = merge(gov_df,pop[,c("GSS","pop_2017")],by.x="region_gss",by.y='GSS')
gov_df$museums_per_100kpop = round(gov_df$n / (gov_df$pop_2017 / 100000),3)
summary(gov_df)
write_xlsx(gov_df,'../plots/geodemo_analysis/population/region_mus17_pop100k_gov.xlsx')

for (gov in unique(gov_df$governance_simpl)){
  print(gov)
  df = subset( gov_df, gov_df$governance_simpl == gov )
  #df = subset( df, !(df$NAME %in% c('Northern Ireland','Scotland','Wales')))
  popsdf = merge(uk_countries_reg_2011_simpl,df,by.x='GSS',by.y='region_gss')
  popsdf = subset( popsdf, !(popsdf$GSS %in% c('N92000002','S92000003','W92000004')))

  fn = paste0("../plots/geodemo_analysis/population/region_mus17_pop100k_map_gov_",gov,'.pdf')
  
  gen_pop_regional_map(popsdf, 'museums_per_100kpop', fn, 
                       paste(gov,'museums by 100,000 residents (2017)'))
  rm(df,popsdf,fn)
}

rm(pop,popsdf,m,gov_df)
rm(lads16,pop16,lads16pop,museums2017lads,musLadStats,mus17lads16pop_summary)


```

## LAD pop vs museums

```{r museums_pop, eval=T}

museums2017sdf = museums2017uksdf # fix

stopifnot(nrow(museums2017sdf)>3000)

pop_outfold = paste0(OUTFOLD,'population/')
#FUN_clean_folder(paste0(OUTFOLD,'population/'),
#                 exclude_files = c('mus2017_region_name_vs_pop17.xlsx',
#                                   'mus2017_region_name_vs_pop17_table.csv'))

# Get LADs
lads16 = spTransform( load_uk_dataset('uk_local_auth_2016-simp01.rds'), proj4string(museums2017sdf))
# UPDATE WITH 2019
lads16 = spTransform( load_uk_dataset('uk_lad_2019-simp005.rds'), proj4string(museums2017sdf))

lads16$area_sqm = gArea(lads16, byid = T)
#lads16$area_ha = conv_unit(lads16$area_sqm, 'm2', 'hectare')
lads16$area_sqkm_geom = round( conv_unit(lads16$area_sqm, 'm2', 'km2'), 1)
#lads16$area_sqmi = conv_unit(lads16$area_sqm, 'm2', 'mi2')
#lads16$area_sqm = NULL
lads16$area_sqkm = lads16$area_sqkm_geom

pop16 = load_uk_dataset('uk_population_est-2016-lad-df.rds')
# UPDATE WITH POP 2018
pop16 = load_uk_dataset('uk_lad_2019_pop18.rds')@data
# get only relevant columns
names(pop16)
#pop16 = pop16[c(1,2,3,4,5)]
pop16 = pop16[c(1,3,6)]  # UPDATE 2019
# merge POP info and LADS
lads16pop = merge(lads16, pop16, by="GSS",all.x=T)
lads16pop$GSS = as.factor(as.character(lads16pop$GSS))
stopifnot( nrow(lads16pop)==382 )

# join museums with units
lads16pop
lads16centr = gCentroid(lads16pop, byid=TRUE)
lads16centr_sdf = SpatialPointsDataFrame(lads16centr,lads16pop@data)

units_over <- sp::over(museums2017sdf, lads16pop[,c(1,3)])
colnames(units_over) = c("UNIT_GSS","UNIT_NAME")
summary(units_over)
museums2017lads <- spCbind(museums2017sdf, units_over)
rm(units_over)

# -------------------------------------------------------
# get museum stats for each Nation/English Region
# -------------------------------------------------------
sdf = museums2017sdf
sdf$UNIT_GSS = sdf$region_name
res_df = FUN_summarise_museum_by_spatial_unit(sdf@data)
res_df = res_df[res_df$VAR %in% c("size_visits_min","size_visits_mean","size_visits_max"),]
pop = read_csv('../plots/geodemo_analysis/population/mus2017_region_name_vs_pop17_table.csv')
res_df = merge(res_df, pop, by.x="UNIT_GSS", by.y="region")
res_df$VAL = NULL
res_df$visits = res_df$n_museums.x
res_df$visits_per100k = round(res_df$visits / (res_df$pop_2017/100000),1)

res_df = FUN_subgroups(res_df,"UNIT_GSS",function(d){
  r = max(d$visits)-min(d$visits)
  d$range = r
  d$min = round(min(d$visits)/1000000,1)
  d$max = round(max(d$visits)/1000000,1)
  d$range_str = paste(round(min(d$visits)/1000000,1), round(max(d$visits)/1000000,1))
  
  d$iqrange = r/4
  d$halfrange = r/2
  return(d)
})

write_xlsx(res_df, paste0(pop_outfold,"mus17_region_visits.xlsx"))
rm(sdf,pop)

# ---------------------------------------------
# get museum stats for each LAD
# ---------------------------------------------
musLadStats = FUN_summarise_museum_by_spatial_unit( museums2017lads@data )

summary(musLadStats)
write_tsv(musLadStats,'../datasets/museums/museums2017_lad2016_counts_long.tsv',na = '')
write_tsv(musLadStats,'../datasets/museums/museums2017_lad2016_counts_long.tsv',na = '')
musLadStats$VARVAL = as.factor( paste0(musLadStats$VAR,'-',musLadStats$VAL) )

musLadStats2 = dcast( musLadStats, UNIT_GSS~VARVAL, value.var = "n_museums" )

musLadStats2 = musLadStats2[ !is.na(musLadStats2$UNIT_GSS), ]
stopifnot(nrow(musLadStats2)>100)

names(musLadStats2)[1] = 'GSS'
names(musLadStats2)[2] = 'n_museums'
musLadStats2$GSS = as.factor(as.character(trimws(musLadStats2$GSS)))
#write_tsv(musLadStats2,'../datasets/museums/museums2017_lad2016_stats_inv.tsv',na = '')

diffSets(musLadStats2$GSS, lads16pop$GSS, 'mus', 'lad')
stopifnot(SameElements(as.character(musLadStats2$GSS), as.character(lads16pop$GSS)))
stopifnot( nrow(musLadStats2) == nrow(lads16pop) )

mus17lads16pop = merge(lads16pop,musLadStats2,by='GSS',all.x=T)
mus17lads16pop$name = NULL
stopifnot(nrow(mus17lads16pop)==nrow(lads16pop))

mus17lads16pop@data$pop2018sqkm = round(mus17lads16pop@data$pop2018 / mus17lads16pop@data$area_sqkm,1)

#View(mus17lads16pop@data)

# ---------------------------------------------
# get densities for museums 2017 per LAD
# ---------------------------------------------
cols = names(mus17lads16pop)[10:ncol(mus17lads16pop)]
stopifnot(cols[1]=='n_museums')
print(cols)
POPUNIT = 100000
for (c in cols){
  perpersonVal = paste0(c,'-per100Kppl')
  #print(paste(c,perpersonVal))
  mus17lads16pop@data[ , perpersonVal] = round( mus17lads16pop@data[ , c] / (mus17lads16pop@data$pop2018 / POPUNIT), 3)
  # estimated_population_mid_2016
  
  persqkmVal = paste0(c,'-per10sqkm')
  mus17lads16pop@data[ , persqkmVal] = round( mus17lads16pop@data[ , c] / (mus17lads16pop@data$area_sqkm/10), 3)
}
rm(c, cols, perpersonVal,persqkmVal)

summary(mus17lads16pop@data)
#View(mus17lads16pop@data[,c("estimated_population_mid_2016","n_museums","area_sqkm","n_museums-per10Kppl","n_museums-perSqkm")])
#summary(mus17lads16pop@data)

# find regions for LADs
units_over <- sp::over(spTransform(lads16centr_sdf, ll_crs), spTransform(uk_countries_reg_2011,ll_crs))
colnames(units_over) = c("LAD_GSS","region")
summary(units_over)
lads16centr_sdf <- spCbind(lads16centr_sdf, units_over)
mus17lads16pop = merge(mus17lads16pop, lads16centr_sdf@data[,c("GSS","region")], by="GSS")
#View(mus17lads16pop@data)
rm(units_over)

# write statistics for LADs
write_tsv(mus17lads16pop@data,'../datasets/museums/museums2017_lad2019_counts.tsv',na = '')
write_xlsx(mus17lads16pop@data, paste0(pop_outfold,'museums2017_lad2019_counts.xlsx',na = ''))

# get stats and generate output
mus17lads16pop_summary = FUN_get_numeric_df_summary(mus17lads16pop@data)
write_xlsx(mus17lads16pop_summary, paste0(pop_outfold, 'museums2017_lad2019_counts_stats.xlsx'))

# -------------------------------------------------
# Plot MAPS for population vs museum data in LADS
# -------------------------------------------------

# simplify geometries for plotting 
mus17lads16pop_simpl = rmapshaper::ms_simplify(mus17lads16pop, keep = .05)
names(mus17lads16pop) = make.names(names(mus17lads16pop))
names(mus17lads16pop_simpl) = make.names(names(mus17lads16pop_simpl))
stopifnot(nrow(mus17lads16pop_simpl)==nrow(mus17lads16pop))
engl_regs = load_uk_dataset('uk_countries_and_eng_regions_2011-simp001.rds')
#engl_regs = load_uk_dataset('eng_regions_2011-simp005.rds') 
engl_regs = rmapshaper::ms_simplify(engl_regs, keep = .07)

plot_density_map_museum_pop <- function(sdf, sdf_simpl, var_col, outfolder, binning, bin_n = 7, breaks=NA,
                                        palette="YlGnBu"){
  print(paste("plot_density_map_museum_pop:",var_col,binning))
  fout = paste0('museum2017_dens_map_LAD-',var_col,'-',binning)
  subtit = get_plot_subtitle(paste0(outfolder,fout))
  #attribution = tm_credits(subtit, position = c("right","bottom"),alpha=.5)
  
  col_palette = palette  #"YlGnBu" #"YlOrRd", "PuBu"
  
  border_col = 'grey40'
  legend_title = paste0(gsub('\\.','\n  ',var_col),'\n[',binning,']')
  if (is.na(breaks)){
    brk = classIntervals( round(as.numeric(sdf_simpl@data[,var_col])), style = binning, n = bin_n)$brks
    brk = round(brk)
  } else {
    brk = breaks
  }
  # base choropleth map of the UK
  m <- tmap::tm_shape(sdf_simpl) + # bbox = bbox, , simplify = .25
    tm_fill(var_col, breaks = brk, #n=bin_n, style=binning,
          palette=col_palette, legend.hist = TRUE,
          border.alpha=0) + #, title = legend_title) + # auto.palette.mapping = T, 
    #tm_scale_bar(width=0.1, position=c("right","bottom")) + 
    #tm_legend(scale=0.95) + #attribution +
    tmap::tm_shape(engl_regs) + tm_borders(col = "white", lwd = 1.8, alpha = 1) +
    tmap::tm_shape(engl_regs) + tm_borders(col = border_col, lwd = .8, alpha = 1) +
    tm_layout(frame=FALSE, legend.title.size=.6, legend.text.size=.4, 
              legend.hist.height=.1, legend.hist.width=.2,
              legend.position = c("right","top")) +
    tm_xlab(subtit, size = .3)
  
  # add London inset
  sdf_London = sdf[ grepl('E090', sdf$GSS), ]
  #print( nrow(sdf_London) )
  stopifnot(nrow(sdf_London)==33)
  m_London <- tm_shape(sdf_London) + tm_fill(var_col, breaks = brk, palette=col_palette,
          border.alpha=0, title = NA, legend.show = F) +
          tm_layout( frame = T, frame.lwd = 1 )
  
  vp_London <- viewport(x = 0.15, y = 0.15, width = 0.24, height = 0.24)
  
  tmap_mode("plot")
  m
  print(m_London, vp = vp_London)
  
  #save_tmap(m, paste0(outfolder, fout,'.png'), width = 4, height = 6)
  tmap_save(m, paste0(fout,'.pdf'), width = 4, height = 6, 
            insets_tm = list(m_London), insets_vp = list(vp_London))
}

cols = names(mus17lads16pop_simpl)[ grepl('per100Kppl',names(mus17lads16pop_simpl)) ]
cols = cols[ !grepl('decade',cols) ]

unlink(paste0(pop_outfold,"museum2017_dens_map_LAD*"),recursive = T)

# NOTE: method to process the color scale when col is a numeric variable. Discrete options
# are "cat", "fixed", "sd", "equal", "pretty", "quantile", "kmeans",
# "hclust", "bclust", "fisher", and "jenks"

# pop density map
#plot_density_map_museum_pop( mus17lads16pop, mus17lads16pop_simpl, 'X2016_people_per_sq_km', pop_outfold, "quantile" )

hist(mus17lads16pop_simpl$n_museums.per100Kppl[mus17lads16pop_simpl$n_museums.per100Kppl<40], 100)

# overall museum density maps
mus_pop_breaks = c(0,5,10,15,20,130)

#plot_density_map_museum_pop(mus17lads16pop, mus17lads16pop_simpl, 'n_museums.per100Kppl', pop_outfold, "jenks")
plot_density_map_museum_pop(mus17lads16pop, mus17lads16pop_simpl, 'n_museums.per100Kppl', pop_outfold, 
                             binning="manual", bin_n=5, breaks=mus_pop_breaks)

#plot_density_map_museum_pop(mus17lads16pop, mus17lads16pop_simpl, 'n_museums.per100Kppl', pop_outfold, 
#                             binning="jenks", bin_n=5)
#plot_density_map_museum_pop(mus17lads16pop, mus17lads16pop_simpl, 'size_mean_visits.sum', pop_outfold, 
#                             binning="kmeans", bin_n=5)

#visit_breaks = c(0,100,500,1000,2000,12000)
#mus17lads16pop_simpl$visit_1000pop = mus17lads16pop_simpl$size_mean_visits.sum.per100Kppl/1000
#mus17lads16pop$visit_1000pop = mus17lads16pop$size_mean_visits.sum.per100Kppl/1000

#hist(mus17lads16pop_simpl$visit_1000pop,100)

#plot_density_map_museum_pop(mus17lads16pop, mus17lads16pop_simpl, 'visit_1000pop', pop_outfold, 
#                             binning="manual", breaks=visit_breaks, palette = "YlOrRd")
#plot_density_map_museum_pop( mus17lads16pop, mus17lads16pop_simpl, 'n_museums.per100Kppl', pop_outfold, "quantile" )
# large museums
#plot_density_map_museum_pop( mus17lads16pop, mus17lads16pop_simpl, 'size.large.per100Kppl', pop_outfold, "jenks", 2 )


# maps for all other density variables
for (var_col in cols){
  plot_density_map_museum_pop( mus17lads16pop, mus17lads16pop_simpl, var_col, pop_outfold, binning='kmeans' )
}

plot_density_map_museum_pop( mus17lads16pop, mus17lads16pop_simpl, "pop2018sqkm", pop_outfold, binning='quantile' )
TODO
# ---------------------------------------------
# LAD 2019 cartograms
# ---------------------------------------------
stopifnot(nrow(mus17lads16pop)>0)

plot_density_map_museum_pop_cartogram = function(sdf, bounds_sdf, var, outf, palette, brk=NA){
  print(paste("plot_density_map_museum_pop_cartogram", var))
  sdf@data$TMP_VAR = round(as.numeric(sdf@data[,var]))
  
  # remove outliers
  outliers_codes = c("E09000001","E06000053","S12000027","S12000023","S12000013","S12000035")
  #sdf@data[sdf@data$GSS %in% outliers_codes,]$TMP_VAR = NA
  
  print(summary(sdf@data$TMP_VAR))
  
  binning = "jenks"
   # "PRGn"
  if (is.na(brk)){
    brk = classIntervals( sdf@data$TMP_VAR, style = binning, n = 5)$brks
  }
  print(brk)
  
  m <- tmap::tm_shape(sdf) + # bbox = bbox, , simplify = .25
    tm_fill("TMP_VAR", breaks = brk, #n=bin_n, style=binning,
          palette=palette, #"YlGnBu", 
          #palette="RdYlBu",
          legend.hist = T,
          border.alpha=0) +
    tm_shape(bounds_sdf) + tm_lines(col = "white", lwd = 3.6) + 
    tm_shape(bounds_sdf) + tm_lines(col = "grey25", lwd = 1.5) + 
    tm_layout(legend.hist.height = .2, legend.hist.width = .4)
  
  tmap_save(m, paste0(outf, "mus17_lad19_cartogram-", binning, "-", var, "-",palette,'.pdf'), width = 4, height = 6)
}

# load cartogram
sdf = load_uk_dataset("uk_lad_2019_square_cartogram.rds")
sdf$GSS = as.factor(sdf$lad_code)
bounds_sdf = load_uk_dataset("uk_lad_2019_square_cartogram_borders.rds")

# merge with museum pop data
diffSets(sdf$GSS, mus17lads16pop$GSS, "carto", "pop")
sdf = merge(sdf, mus17lads16pop@data, by="GSS", all.x=T)
sdf$n_museums_z = scale(sdf$n_museums)
sdf$n_museums.per100Kppl_z = scale(sdf$n_museums.per100Kppl)
hist(sdf$n_museums.per100Kppl[sdf$n_museums.per100Kppl < 20],breaks = 100)

plot_density_map_museum_pop_cartogram(sdf, bounds_sdf, "n_museums", pop_outfold, palette="YlOrRd") # , brk=c(1,5,10,20,40,80)
plot_density_map_museum_pop_cartogram(sdf, bounds_sdf, "n_museums.per100Kppl", pop_outfold, palette="YlGnBu",brk=mus_pop_breaks)
# , brk=c(0,.25,.5,1,2,20)

mus17lads16pop_simpl 

plot_density_map_museum_pop_cartogram(sdf, bounds_sdf, "n_museums_z", pop_outfold, palette="RdYlBu")
plot_density_map_museum_pop_cartogram(sdf, bounds_sdf, "n_museums.per100Kppl_z", pop_outfold, palette="RdYlBu")

# visits (FLAWED)
#sdf$visit_1000pop = sdf$size_mean_visits.sum.per100Kppl/1000
#sdf$visit_1000pop_z = round(scale(sdf$visit_1000pop),1)  # z scores
#sdf$visits_pop = round((sdf$size_mean_visits.sum / sdf$pop2018),2)
#sdf$visits_pop_z = round(scale(sdf$visits_pop),2)
#summary(sdf$visit_1000pop_z)
#hist(sdf$visit_1000pop[sdf$visit_1000pop<3000], 100)

#plot_density_map_museum_pop_cartogram(sdf, bounds_sdf, "size_mean_visits.sum", pop_outfold, palette="YlOrRd")
#plot_density_map_museum_pop_cartogram(sdf, bounds_sdf, "visit_1000pop", pop_outfold, palette="YlOrRd",
#                                      brk = visit_breaks)

summary(sdf$governance_simpl.independent.per100Kppl)
hist(sdf$governance_simpl.independent.per100Kppl,50)
summary(sdf$governance_simpl.government.per100Kppl)
hist(sdf$governance_simpl.government.per100Kppl,50)

brk = c(0,2,5,10,20,110)
plot_density_map_museum_pop_cartogram(sdf, bounds_sdf, "governance_simpl.independent.per100Kppl", 
                                      pop_outfold, palette="YlGnBu", brk=brk) # brk = c(0,100,500,1000,2000,12000)
plot_density_map_museum_pop_cartogram(sdf, bounds_sdf, "governance_simpl.government.per100Kppl", 
                                      pop_outfold, palette="YlGnBu", brk=brk) # brk = c(0,100,500,1000,2000,12000)

write_xlsx(sdf@data, paste0(pop_outfold, "mus17_lads_pop_visits.xlsx"))

# ------------------------------------------------------------ 
# Bivariate maps
# ------------------------------------------------------------ 

gen_bivariate_choro_lads_map = function(sdf, bounds_sdf, cartogram_sdf, cartogram_bounds_sdf, 
                                        var1, var2, lab1, lab2, method, colours){
  # biv choro geographical map
    fn = paste0(pop_outfold, "bivar_map-",lab1,'-',lab2,'-',method,"-geog.pdf")
  m = bivariate.choropleth(sdf, c(var1,var2), c(lab1,lab2), fn, method, colours)
  m = m + tm_shape(bounds_sdf) + tm_borders(col = "white", lwd = 4) + 
    tm_shape(bounds_sdf) + tm_borders(col = "grey25", lwd = 1.6) 
    #tm_layout(legend.hist.height = .2, legend.hist.width = .4)
  print(fn)
  tmap_save(m, fn)
  
  # biv choro cartogram map
  fn = paste0(pop_outfold, "bivar_map-",lab1,'-',lab2,'-',method,"-cartogram.pdf")
  m = bivariate.choropleth(cartogram_sdf, c(var1,var2), c(lab1,lab2), fn, method, colours)
  m = m + tm_shape(cartogram_bounds_sdf) + tm_lines(col = "white", lwd = 8) + 
    tm_shape(cartogram_bounds_sdf) + tm_lines(col = "grey25", lwd = 2.5) 
    #tm_layout(legend.hist.height = .2, legend.hist.width = .4)
  print(fn)
  tmap_save(m, fn)
}

cartogram_sdf = sdf 
cartogram_bounds_sdf = bounds_sdf

# plot vars
mus17lads16pop_simpl$pop2018thou = mus17lads16pop_simpl$pop2018 / 1000
for (v in c("n_museums","pop2018thou","pop2018sqkm","n_museums.per100Kppl",
            "governance_simpl.government.per100Kppl","governance_simpl.independent.per100Kppl")){
  fn1 = paste0(pop_outfold,"var_hists-",v,'.pdf')
  g = ggplot(mus17lads16pop_simpl@data, aes_string(x=v)) +
    theme_light() + 
    geom_histogram(position="identity", bins = 10)
  # , fill="gray50", color="gray50"
  ggsave(fn1,g,width = 1.7, height = 1.7)
}

gen_bivariate_choro_lads_map(mus17lads16pop_simpl, engl_regs, cartogram_sdf, cartogram_bounds_sdf,
                             "governance_simpl.government.per100Kppl",
                             "governance_simpl.independent.per100Kppl","gov100k","indep100k",
                             "jenks","GnBu") # BuPu

gen_bivariate_choro_lads_map(mus17lads16pop_simpl, engl_regs, cartogram_sdf, cartogram_bounds_sdf,
                             "governance_simpl.government.per10sqkm",
                             "governance_simpl.independent.per10sqkm","gov10sq","indep10sq",
                             "jenks","GnBu")

gen_bivariate_choro_lads_map(mus17lads16pop_simpl, engl_regs, cartogram_sdf, cartogram_bounds_sdf,
                             "governance_simpl.government",
                             "governance_simpl.independent","gov","indep",
                             "jenks","GnBu")

gen_bivariate_choro_lads_map(mus17lads16pop_simpl, engl_regs, cartogram_sdf, cartogram_bounds_sdf,
                             "n_museums","pop2018", 
                             "mus","pop", "jenks", "RdBu") # PuOr,RdBu, BuPu

gen_bivariate_choro_lads_map(mus17lads16pop_simpl, engl_regs, cartogram_sdf, cartogram_bounds_sdf,
                             "n_museums","pop2018", 
                             "mus","pop", "fisher", "RdBu") # PuOr,RdBu, BuPu

gen_bivariate_choro_lads_map(mus17lads16pop_simpl, engl_regs, cartogram_sdf, cartogram_bounds_sdf,
                             "n_museums.per100Kppl","pop2018", 
                             "mus100k","pop", "fisher", "RdBu") # PuOr,RdBu, BuPu

gen_bivariate_choro_lads_map(mus17lads16pop_simpl, engl_regs, cartogram_sdf, cartogram_bounds_sdf,
                             "n_museums.per100Kppl","pop2018sqkm", 
                             "mus100k","popkm", "quantile", "RdBu") # PuOr,RdBu, BuPu

gen_bivariate_choro_lads_map(mus17lads16pop_simpl, engl_regs, cartogram_sdf, cartogram_bounds_sdf,
                             "n_museums.per100Kppl","pop2018sqkm", 
                             "mus100k","popkm", "fisher", "RdBu") # PuOr,RdBu, BuPu

gen_bivariate_choro_lads_map(mus17lads16pop_simpl, engl_regs, cartogram_sdf, cartogram_bounds_sdf,
                             "n_museums.per100Kppl","pop2018sqkm", 
                             "mus100k","popkm", "fisher", "RdBu") # PuOr,RdBu, BuPu


#gen_bivariate_choro_lads_map(mus17lads16pop_simpl, engl_regs, cartogram_sdf, cartogram_bounds_sdf,
#                             "n_museums.per100Kppl","pop2018", 
#                             "mus100k","pop", "quantile", "RdBu") # PuOr,RdBu, BuPu



gen_bivariate_choro_lads_map(mus17lads16pop_simpl, engl_regs, cartogram_sdf, cartogram_bounds_sdf,
                             "n_museums.per100Kppl","pop2018", 
                             "mus100k","pop", "quantile", "RdBu") # PuOr,RdBu, BuPu

# plot cartograms
#for (col in c("n_museums","n_museums.per10Kppl","governance_simpl.government.per10Kppl","governance_simpl.independent.per10Kppl")){
#  plot_density_map_museum_pop_cartogram(sdf, bounds_sdf, col, pop_outfold)
#}

rm(cartogram_sdf,cartogram_bounds_sdf)

# -------------------------------------------------
# population LAD 2019 vs museums 2017 (regional box plot) 
# -------------------------------------------------

nrow(sdf)

summary(sdf$n_museums.per100Kppl)
ggplot(sdf@data[sdf@data$n_museums.per100Kppl <= 20,], aes(x=region_name, y=`n_museums.per100Kppl`, color=region_name)) + 
  geom_boxplot(notch=T) + theme_light()

rm(engl_regs, cols, mus17lads16pop, mus17lads16pop_simpl, var_col, pop_outfold)

```





# Museums in spatial units (OA/LSOA joins)

Also extra datasets for web platform in ../datasets/extra_data/

Check MappingMuseums/MuseumData/AdditionalData/ExtraDatasets

```{r museums_oa, eval=T}
oadf = load_uk_dataset("uk_oa_2011-full.rds")
oadf

# SPATIAL JOIN between all museums and OAs 2011
units_over <- over(spTransform(museums_bg, proj4string(oadf)), oadf[,c("GSS")])
colnames(units_over) = c("OA_GSS")
museums_oa = spCbind(museums_bg, units_over)
museums_oa = museums_oa@data[,c('project_id',"OA_GSS")]
museums_oa$project_id = trimws(museums_oa$project_id)
museums_oa$OA_GSS = trimws(museums_oa$OA_GSS)
outtable = museums_oa
names(outtable)[2] = 'OA2011_GSS'
write_tsv(outtable,'../datasets/extra_data/museumsall_gss_oa2011.tsv',na = '')
rm(outtable)
rm(oadf,units_over)

# missing values
missing_vals = museums_oa[is.na(museums_oa$OA_GSS),]
write_tsv(missing_vals,'../datasets/extra_data/museumsall_gss_oa2011_missing.tsv',na = '')
rm(missing_vals)

# SPATIAL JOIN between all museums and LSOAs 2011
lsoadf = load_uk_dataset("uk_lsoa_2011-full.rds")

units_over <- over(spTransform(museums_bg, proj4string(lsoadf)), lsoadf[,c("GSS")])
colnames(units_over) = c("LSOA_GSS")
museums_lsoa = spCbind(museums_bg, units_over)
museums_lsoa = museums_lsoa@data[,c('project_id',"LSOA_GSS")]
museums_lsoa$project_id = trimws(museums_lsoa$project_id)
museums_lsoa$LSOA_GSS = trimws(museums_lsoa$LSOA_GSS)
outtable = museums_lsoa
names(outtable)[2] = 'LSOA2011_GSS'
write_tsv(outtable,'../datasets/extra_data/museumsall_gss_lsoa2011.tsv',na = '')

# missing values
missing_vals = museums_lsoa[is.na(museums_lsoa$LSOA_GSS),]
write_tsv(missing_vals,'../datasets/extra_data/museumsall_gss_lsoa2011_missing.tsv',na = '')
rm(missing_vals)

rm(outtable)
rm(lsoadf,units_over)
```

# Museums in OAC

Calculate count stats of museum attributes vs Output area classification (OAC)

Also some extra datasets for web platform
(Check MappingMuseums/MuseumData/AdditionalData/ExtraDatasets)

```{r museums_oac, eval=T}

oac_outfold = paste0(OUTFOLD,'oac/')
#unlink(paste0(oac_outfold,"*"), recursive = T)
FUN_gen_last_update_file(oac_outfold)

#FUN_copy_doc_uk( "ONS_output_area_classification/2011 OAC groups.png", oac_outfold)
#FUN_copy_doc_uk( "ONS_output_area_classification/2011 OAC supergroups.png", oac_outfold)
#FUN_copy_doc_uk( "ONS_output_area_classification/2011 OAC subgroups.png", oac_outfold)
#FUN_copy_doc_uk( "ONS_output_area_classification/categories pen portraits-output areas.pdf", oac_outfold)
#FUN_copy_doc_uk( "ONS_output_area_classification/categories pen portraits-LAD-v2.pdf", oac_outfold)
#FUN_copy_doc_uk( "ONS_output_area_classification/2011 oac list all categories.xlsx", oac_outfold)
#FUN_copy_doc_uk( "ONS_output_area_classification/categories pen portraits-lad-descriptions.pdf", oac_outfold)

# this is needed
#oa_df = read_tsv('../datasets/extra_data/museumsall_gss_lsoa2011.tsv')
stopifnot(nrow(museums_oa)>0)

# -------------------------
# prep OAC data (LAD + OA)
# -------------------------
# Load OAC (LAD level)
oaclad2011sdf = load_uk_dataset( "uk_output_area_class_lad_sdf_2011.rds" )

stopifnot(nrow(oaclad2011sdf)==391)
# gen new fields
oaclad2011sdf$supergroup_name_long = as.factor(paste0(oaclad2011sdf$supergroup_code, '-', oaclad2011sdf$supergroup_name))
oaclad2011sdf$group_name_long = as.factor(paste0(oaclad2011sdf$group_code, '-', oaclad2011sdf$group_name))
oaclad2011sdf$subgroup_name_long = as.factor(paste0(oaclad2011sdf$subgroup_code, '-', oaclad2011sdf$subgroup_name))

write_tsv(oaclad2011sdf@data[,c(1,2,4,6:11,71:73)], '../datasets/extra_data/output_area_class-lad2011.tsv',na = '')

# gen stats
df = p_summary_list( oaclad2011sdf$supergroup_name_long, "OAC_LAD_stats-supergroup" )
write_xlsx(df, paste0(oac_outfold, "OAC_LAD_stats-supergroup.xlsx") )
saveRDS(df, paste0(oac_outfold, "OAC_LAD_stats-supergroup.rds") )

df = p_summary_list( oaclad2011sdf$group_name_long, "OAC_LAD_stats-group" )
write_xlsx(df, paste0(oac_outfold, "OAC_LAD_stats-group.xlsx") )
saveRDS(df, paste0(oac_outfold, "OAC_LAD_stats-group.rds") )

df = p_summary_list( oaclad2011sdf$subgroup_name_long, "OAC_LAD_stats-subgroup" )
write_xlsx(df, paste0(oac_outfold, "OAC_LAD_stats-subgroup.xlsx") )
saveRDS(df, paste0(oac_outfold, "OAC_LAD_stats-subgroup.rds") )
rm(df)

# load OAC OAs
oac_oa = load_uk_dataset("uk_output_area_class_oa_2011.rds")
nrow(oac_oa)

#summary(museums_oa$OA_GSS)
oac_oa$supergroup_name_long = as.factor(paste0(oac_oa$supergroup_code, '-', oac_oa$supergroup_name))
oac_oa$group_name_long = as.factor(paste0(oac_oa$group_code, '-', oac_oa$group_name))
oac_oa$subgroup_name_long = as.factor(paste0(oac_oa$subgroup_code, '-', oac_oa$subgroup_name))

write_tsv(oac_oa,'../datasets/extra_data/output_area_class-oa2011.tsv',na = '')

# gen stats
df = p_summary_list( oac_oa$supergroup_name_long, "OAC_OA_stats-supergroup" )
write_xlsx(df, paste0(oac_outfold, "OAC_OA_stats-supergroup.xlsx") )
saveRDS(df, paste0(oac_outfold, "OAC_OA_stats-supergroup.rds") )

df = p_summary_list( oac_oa$group_name_long, "OAC_OA_stats-group" )
write_xlsx(df, paste0(oac_outfold, "OAC_OA_stats-group.xlsx") )
saveRDS(df, paste0(oac_outfold, "OAC_OA_stats-group.rds") )

df = p_summary_list( oac_oa$subgroup_name_long, "OAC_OA_stats-subgroup" )
write_xlsx(df, paste0(oac_outfold, "OAC_OA_stats-subgroup.xlsx") )
saveRDS(df, paste0(oac_outfold, "OAC_OA_stats-subgroup.rds") )
rm(df)

# --------------------------------
## OAC stats vs museum attrib
#--------------------------------

# overall museum category counts for OACs
FUN_gen_museums_oac_counts = function(mdf, prefix, oacStatsFile ){
  print(paste("FUN_gen_museums_oac_counts", prefix, oacStatsFile ))
  stopifnot(class(mdf)=='data.frame', "UNIT_GSS" %in% names(mdf), nchar(prefix)>0)
  stopifnot( c("subgroup_name_long","group_name_long","supergroup_name_long") %in% names(mdf))
  
  gen_oac_overall_stats = function(vals, prefix, grouptype){
    #print("gen_oac_overall_stats")
    df = p_summary_list(vals, paste0(prefix,"-",grouptype))
    tot = readRDS( paste0(oac_outfold, oacStatsFile,"-",grouptype,".rds") )
    stopifnot(any(nrow(tot)>0),any(ncol(tot)>0))
    # add area totals
    df2 = merge(df, tot, by='VAL.x', all.x=T,suffixes = c(".mus",".areas"))
    stopifnot(sum(df2$PC.areas) > 0)
    # calculate divergence
    df2$mus_divergence_PC = df2$PC.mus - df2$PC.areas
    #View(df2)
    write_xlsx(df2, paste0(oac_outfold, prefix,"-",grouptype,'.xlsx'))
    rm(df2,tot,df)
  }
  
  gen_oac_overall_stats(mdf$supergroup_name_long, prefix, "supergroup")
  gen_oac_overall_stats(mdf$group_name_long, prefix, "group")
  gen_oac_overall_stats(mdf$subgroup_name_long, prefix, "subgroup")
  
  # compare two variables
  for (a in c("subject_matter_simpl_aggr", "governance","governance_simpl","size",
              'accreditation')){
    for (g in c("subgroup_name_long","group_name_long","supergroup_name_long")){
      fout = paste0(oac_outfold, prefix, '-2var-',g,"-",a)
      print(fout)
      fout = gsub("_long",'',fout)
      grouptype = gsub("_name_long",'',g)
      # get totals for each OAC category
      # generate plots (data and heatmap)
      tot = readRDS( paste0(oac_outfold, oacStatsFile,"-",grouptype,".rds") )
      stopifnot(any(nrow(tot)>0), any(ncol(tot)>0))
      
      FUN_gen_freq_matrix(mdf, a, g, fout, rowPercents = tot[,c('VAL.x','PC')])
      rm(fout,rowPercents,grouptype,tot)
    }
  }
  rm(a,g)
  
  museums_without_unit = subset(mdf, is.na(mdf$UNIT_GSS) )
  
  rm(museums_without_unit)
}

FUN_gen_museums_oac_counts_for_units = function(mdf, prefix){
  print(paste("FUN_gen_museums_oac_counts_for_units",prefix))
  # calculate spatial stats for UNIT_GSS
  #View(mdf)
  museum_sp_stats_df = FUN_summarise_museum_by_spatial_unit( mdf )
  museum_sp_stats_df = dcast( museum_sp_stats_df, UNIT_GSS~VAL, value.var = "n_museums" )
  x = as.character(museum_sp_stats_df$UNIT_GSS)
  x[ is.na(x) ] <- 'NO_UNIT'
  museum_sp_stats_df$UNIT_GSS = x
  rm(x)
  row.names(museum_sp_stats_df) = museum_sp_stats_df$UNIT_GSS
  
  # correlations
  #corm = cor(museum_sp_stats_lad_df[,seq(2,ncol(museum_sp_stats_lad_df))])
  
  return(museum_sp_stats_df)
}

# ----------------------------------------
# ----------------------------------------
# OAC OAs 2011 for each museum
# + datasets for Web Platform
# ----------------------------------------
# ----------------------------------------

# join museums with OA codes
museums2017_bg <- merge( museums2017sdf, museums_oa, by="project_id", all.x=T )
museums2017_bg$UNIT_GSS = as.factor(museums2017_bg$OA_GSS)

# merge museums with OAC OA attribs
museums2017_bg = merge(museums2017_bg, oac_oa, by.x="UNIT_GSS", by.y="GSS", all.x = T)
stopifnot(nrow(museums2017_bg)==nrow(museums2017sdf),nrow(museums2017_bg)>0)
#names(museums2017_bg)

museum_oac_oa_df = FUN_gen_museums_oac_counts(museums2017_bg@data, "mus_OAC_OA", "OAC_OA_stats")

# same stats only for independent museums (for Fiona 14/5/2020)
museumind_oac_oa_df = FUN_gen_museums_oac_counts(museums2017_bg@data[museums2017_bg@data$governance_simpl=="independent", ], "mus_indep_OAC_OA", "OAC_OA_stats")


stopifnot(nrow(museum_oac_oa_df)>0)

# write museum data for museum databasear2, "vs", var1, 
# Name similar to museums17_lsoa_deprivation15_deciles.tsv
names(museums2017_bg)
df = museums2017_bg[,c(2,1,48:60)]
names(df)
names(df)[2] = 'OA_GSS'
FUN_save_museum_dataset( as.data.frame(df), 'museums17_oa_oaclassif11_categ')
rm(df)

rm(museums2017_bg,museum_oac_oa_df)

# ----------------------------------------
#  OAC LADs 2011 for each museum
# ----------------------------------------

# join museums with OAC LAD 2011 (museums 2017)
stopifnot(nrow(museums2017sdf)>0, nrow(oaclad2011sdf)>0)
units_over <- over(museums2017sdf, oaclad2011sdf[,c("GSS","NAME")])
colnames(units_over) = c("UNIT_GSS","UNIT_NAME")
summary(units_over)
museums2017_bg <- spCbind(museums2017sdf, units_over)
rm(units_over)

spatialjointable = museums2017_bg@data[,c("project_id","UNIT_GSS")]
names(spatialjointable) = c("project.id","LAD2011_GSS")
write_tsv(spatialjointable,'../datasets/extra_data/museums2017_gss_lad2011.tsv',na = '')
rm(spatialjointable)

# join museums with OAC LAD 2011 (all museums)
stopifnot(nrow(museums_bg)>0, nrow(oaclad2011sdf)>0)
units_over <- over(museums_bg, oaclad2011sdf[,c("GSS","NAME")])
colnames(units_over) = c("UNIT_GSS","UNIT_NAME")
summary(units_over)
allmuseums_bg <- spCbind(museums_bg, units_over)
rm(units_over)

spatialjointable = allmuseums_bg@data[,c("project_id","UNIT_GSS")]
names(spatialjointable) = c("project.id","LAD2011_GSS")
write_tsv(spatialjointable,'../datasets/extra_data/museumsall_gss_lad2011.tsv',na = '')
rm(allmuseums_bg)
rm(spatialjointable)

# get relevant cols
oaclad2011df = oaclad2011sdf@data[,c(1,6:11,71,72,73)]
names(oaclad2011df)
museums_oac_df = merge(museums2017_bg@data, oaclad2011df, by.x="UNIT_GSS", by.y="GSS" )

museum_oac_lad_df = FUN_gen_museums_oac_counts(museums_oac_df, "mus_OAC_LAD", "OAC_LAD_stats")

museum_oac_lad_units_df = FUN_gen_museums_oac_counts_for_units(museums_oac_df,"mus_OAC_LAD")
#View(museum_oac_lad_units_df)
write_xlsx(museum_oac_lad_units_df,paste0(oac_outfold,'museum2017_lad_stats_for_OAC.xlsx'))

if (F){
  # same stats only for independent museums (LAD geodemo) (for Fiona 29/5/2020)
  df = FUN_gen_museums_oac_counts(museums_oac_df[museums_oac_df$governance_simpl=="independent",], "indep_mus_OAC_LAD", "OAC_LAD_stats")
  write_xlsx(df, paste0(oac_outfold,'museum2017_indep_lad_stats_for_OAC.xlsx'))
  
  museum_oac_lad_units_df = FUN_gen_museums_oac_counts_for_units(museums_oac_df[museums_oac_df$governance_simpl=="independent",],"indep_mus_OAC_LAD")
  View(museum_oac_lad_units_df)
  write_xlsx(museum_oac_lad_units_df, paste0(oac_outfold,'museum2017_indep_lad_stats_for_OAC_units.xlsx'))
}



rm(museum_oac_lad_units_df)
rm(museums2017_bg, oac_oa, oaclad2011sdf)
```
## Geodemo paper data

```{r}

# LAD vs governance
div_df = read_excel(paste0(oac_outfold, 'mus_OAC_LAD-2var-group_name-governance--diverg.xlsx'))


```


# Museums urban/rural

## England RUC
Data about England
* https://www.gov.uk/government/statistics/2011-rural-urban-classification
* https://www.ons.gov.uk/methodology/geography/geographicalproducts/ruralurbanclassifications/2011ruralurbanclassification
* https://www.ons.gov.uk/methodology/geography/geographicalproducts/areaclassifications/2011areaclassifications/datasets

```{r museum_sp_rural_engl, eval=T}
ruc_outfold = paste0(OUTFOLD,'ruralurban/')
unlink(paste0(ruc_outfold,"*"),recursive = T)
FUN_gen_last_update_file(ruc_outfold)

stopifnot(nrow(museums2017sdf)>3000)

# copy documentation
FUN_copy_doc_uk( "GOV_urban_rural_classification/2011 Rural-Urban Classification for Local Authority Districts in England.pdf", ruc_outfold)
FUN_copy_doc_uk( "GOV_urban_rural_classification/The 2011 Rural-Urban Classification for Output Areas in England.pdf", ruc_outfold)

# ------------------------------------------
# RUC: prep data
# ------------------------------------------
# load data
engl_urban_rural_lad_2011 = load_uk_dataset("engl_urban_rural_lad_2011.rds")
lads = load_uk_dataset('uk_local_auth_alt_2011-full.rds')

diffSets( lads$GSS, engl_urban_rural_lad_2011$GSS, "lad", 'rural' )
rm(uk_local_auth_2011)

# output date for web application
write_tsv(engl_urban_rural_lad_2011,'../datasets/extra_data/urbanrural2011-england-lad2011.tsv',na = '')

# ------------------------------------------
# RUC: join museums with LADs
# ------------------------------------------
units_over <- sp::over(museums2017sdf, lads[,c(1,2)])
colnames(units_over) = c("UNIT_GSS","UNIT_NAME")
summary(units_over)
museums2017_bg <- spCbind(museums2017sdf, units_over)
rm(units_over)

mdf = merge( museums2017_bg, engl_urban_rural_lad_2011, by.x = 'UNIT_GSS', by.y = 'GSS', all = T )
stopifnot(nrow(museums2017_bg)==nrow(mdf))
rm(museums2017_bg)
mdf$RUC_CAT = as.character(mdf$RUC_CAT)
mdf$RUC_CAT[is.na(mdf$RUC_CAT)] = 'NOT_ENGL'
mdf$RUC_CAT_LONG = paste0(mdf$RUC_CODE,'-',mdf$RUC_CAT)
mdf$RUC_CAT_LONG = as.factor(mdf$RUC_CAT_LONG)

# generate stats for RUC LADs vs museums
summary(mdf)
engl_urban_rural_lad_2011$RUC_CAT_LONG = paste0(engl_urban_rural_lad_2011$RUC_CODE,'-',engl_urban_rural_lad_2011$RUC_CAT)
df = p_summary_list(mdf$RUC_CAT_LONG[mdf$RUC_CAT_LONG!='NA-NOT_ENGL'],"museums-RUC_LAD_ENGL")
tot = p_summary_list(engl_urban_rural_lad_2011$RUC_CAT_LONG,"engl_urban_rural_lad_2011")
df = merge(df, tot, by.x='VAL.x', by.y="VAL.x", all.x=T, suffixes = c(".mus",".areas"))
df$mus_divergence_PC = df$PC.mus - df$PC.areas
write_xlsx(df, paste0(ruc_outfold,'museums_in_engl_rural_urban_LAD_2011.xlsx'))

rm(df)

# MAP museums with RUC (LADs)
p = tmap::tm_shape(lads, simplify=.05) + tm_borders(col='gray',lwd = 0.2) + 
  #tm_text("GSS",size = .1) + 
  tmap::tm_shape(mdf) + tm_dots(col="RUC_CAT",size = .01,alpha=.5)
tmap::save_tmap(p, paste0( ruc_outfold, 'museums_engl_ruc11_LAD_map.pdf' ))

# compare 2 VARIABLES  for museums RUC in LADs
for (a in c("governance","governance_simpl",'accreditation',"size",
            "subject_matter_simpl_aggr")){
  for (g in c("RUC_CAT_LONG")){
    fout = paste0( ruc_outfold, 'mus_ruc11_LAD-2var-',g,"-",a )
    dd = subset( mdf@data, mdf@data$RUC_CAT_LONG != 'NA-NOT_ENGL')
    stopifnot(nrow(dd)>0)
    FUN_gen_freq_matrix( dd, a, g, fout, rowPercents = tot[,c('VAL.x','PC')])
    rm(dd)
  }
}

rm(mdf, p, engl_urban_rural_lad_2011, tot)

# ------------------------------------------
# RUC: join museums with OAs
# ------------------------------------------

stopifnot(nrow(museums_oa)>0, nrow(museums2017sdf)>0)
names(museums2017sdf)

uk_urban_rural_oa_2011 = load_uk_dataset("englwal_urban_rural_oa_2011.rds")

# output date for web application
write_tsv(uk_urban_rural_oa_2011,'../datasets/extra_data/urbanrural2011-engwales-oa2011.tsv',na = '')

# merge OAs
mdf = merge(museums2017sdf,museums_oa,by.x='project_id',by.y="project_id")
nrow(mdf)
mdf$UNIT_GSS = as.factor(mdf$OA_GSS)

# merge RUC data with museums
mdf = merge( mdf, uk_urban_rural_oa_2011, by.x="UNIT_GSS", by.y="GSS" )
mdf$RUC_CAT = as.character(mdf$RUC_CAT)
mdf$RUC_CAT[is.na(mdf$RUC_CAT)] = 'NOT_ENGL'

mdf$RUC_CAT_LONG = as.factor(paste0(mdf$RUC_CODE, "-", mdf$RUC_CAT))
summary(mdf$RUC_CAT_LONG)

# generate stats for all museums for RUC
df = p_summary_list( mdf$RUC_CAT_LONG[mdf$RUC_CAT_LONG!='NA-NOT_ENGL'], "museums-RUC_OA_ENGL")

uk_urban_rural_oa_2011$RUC_CAT_LONG = as.factor(paste0(uk_urban_rural_oa_2011$RUC_CODE, '-', uk_urban_rural_oa_2011$RUC_CAT))
tot = p_summary_list(uk_urban_rural_oa_2011$RUC_CAT_LONG,"uk_urban_rural_oa_2011")
df = merge(df, tot, by.x='VAL.x', by.y="VAL.x", all.x=T, suffixes = c(".mus",".areas"))
df$mus_divergence_PC = df$PC.mus - df$PC.areas
write_xlsx(df, paste0(ruc_outfold,'museums_in_engwal_rural_urban_OA_2011.xlsx'))
rm(df)

# compare 2 VARIABLES  for museums RUC in OAs
for (a in c("governance","governance_simpl","size","subject_matter_simpl_aggr")){
  for (g in c("RUC_CAT_LONG")){
    fout = paste0( ruc_outfold, 'mus_ruc11_OA-2var-',g,"-",a )
    FUN_gen_freq_matrix( subset( mdf@data, mdf@data$RUC_CAT_LONG != 'NA-NOT_ENGL'), 
                         a, g, fout,
                         rowPercents = tot[,c('VAL.x','PC')])
  }
}

# Write data for museum database
names(mdf@data)
nrow(mdf@data)
df = mdf@data[,c(2,1,47:53)]
names(df)
names(df)[2] = 'OA_GSS'
FUN_save_museum_dataset(as.data.frame(df),'museums17_oa_ruralurban11_categ')
rm(df,tot)

# MAP museums with RUC (OAs)
p = tmap::tm_shape(lads, simplify=.05) + tm_borders(col='gray',lwd = 0.2) + 
  #tm_text("GSS",size = .1) + 
  tmap::tm_shape(mdf) + tm_dots(col="RUC_CAT_LONG",size = .01,alpha=.5)
tmap::save_tmap(p, paste0( ruc_outfold, 'museums_engwal_ruc11_OA_map.pdf' ))

rm(mdf, p, uk_urban_rural_oa_2011, lads)
```


## Scotland SGUR

```{r museum_sp_rural_scot, eval=T}

scotland_urban_rural_2014_lsoa_2011 = load_uk_dataset('scotland_urban_rural_2014_lsoa_2011.rds')
# output date for web application
write_tsv(scotland_urban_rural_2014_lsoa_2011,'../datasets/extra_data/urbanrural2014-scotland-lsoa2011.tsv',na = '')


rm(scotland_urban_rural_2014_lsoa_2011)
```

## NI Urban Rural

```{r museum_sp_rural_ni, eval=T}

nirl_urban_rural_lsoa_2015 = load_uk_dataset('nirl_urban_rural_lsoa_2015.rds')
# output date for web application
write_tsv(nirl_urban_rural_lsoa_2015,'../datasets/extra_data/urbanrural2015-nireland-lsoa2011.tsv',na = '')

rm(nirl_urban_rural_lsoa_2015)
```

# Museums and deprivation


```{r museum_sp_depriv, eval=T}

stopifnot(nrow(museums2017sdf)>0,ncol(museums2017sdf)==50)
depriv_outfold = paste0(OUTFOLD,'deprivation/')
unlink(paste0(depriv_outfold,"*"),recursive = T)
FUN_gen_last_update_file(depriv_outfold)

# copy documentation
FUN_copy_doc_uk( "GOV_deprivation/English_Index_of_Multiple_Deprivation_2015_-_Infographic.pdf", depriv_outfold)
FUN_copy_doc_uk( "GOV_deprivation/English_Indices_of_Deprivation_2015_-_Statistical_Release.pdf", depriv_outfold)

# ------------------------------------------
# Deprivation: prep data
# ------------------------------------------

lsoa = load_uk_dataset('uk_lsoa_2011-full.rds')
lsoa = spTransform(lsoa, british_grid_crs)

# load all deprivation deciles
depriv = load_uk_dataset('deprivation_index_deciles_merged_uk_2017_lsoa2011.rds')
write_tsv(depriv,'../datasets/extra_data/deprivation_index_deciles_merged_uk_2017_lsoa2011.tsv',na = '')

summary(depriv)

depriv_cols = c("combined_idx_dec","income","employment","education","health","crime","housing","services")

depriv15sdf = merge(lsoa, depriv, by.x='GSS', by.y='GSS', all.x=F, all.y=T)
stopifnot(nrow(lsoa)==nrow(depriv))
stopifnot(nrow(lsoa)==nrow(depriv15sdf))
rm(depriv,lsoa)

#nrow(depriv15sdf)
#names(depriv15sdf)
depriv15sdf$GSS = as.factor(as.character(depriv15sdf$GSS))
depriv15sdf$NAME = as.factor(as.character(depriv15sdf$NAME))
names(depriv15sdf)

# SPATIAL JOIN between Museums 2017 and English LSOAs
units_over <- sp::over( museums2017sdf, depriv15sdf )
colnames(units_over)[1:2] = c("UNIT_GSS","UNIT_NAME")
mus_depriv_sdf <- spCbind( museums2017sdf, units_over )
names(mus_depriv_sdf)

tablejoin = mus_depriv_sdf@data[,c("project_id","UNIT_GSS")]
names(tablejoin) = c('project.id','LSOA2011_GSS')
write_tsv(tablejoin,'../datasets/extra_data/museums2017_gss_lsoa2011.tsv',na = '')
rm(tablejoin)
rm(units_over)

format_depr_index = function(x){
  x = as.numeric(x)
  nums = x[!is.na(x)]
  stopifnot(nums > 0, nums <= 10)
  as.factor(sprintf("d%02d", x))
}

# write dataset for museum database
out_df = mus_depriv_sdf[,c("project_id","UNIT_GSS",depriv_cols,'country')]@data
names(out_df) = gsub('\\.','_', names(out_df))
names(out_df)[2] = 'LSOA_GSS'
FUN_save_museum_dataset(as.data.frame(out_df),"museums17_lsoa_deprivation15_deciles")
rm(out_df)

# get stats about LSOAs and museums
mus_gss = mus_depriv_sdf$UNIT_GSS
nrow(mus_depriv_sdf)
#nrow(lsoa)
#engl_lsoa_n = nrow(lsoa[lsoa$COUNTRY=='England',])
df = as.data.frame(table(mus_gss))
df1 = p_summary_list(as.factor(df$Freq),'lsoas_stats_re_museums')
#stopifnot(engl_lsoa_n==sum(df1$Freq))
names(df1)[1:2] = c('N_MUSEUMS_2017','N_LSOAS')
write_xlsx(df1, paste0(depriv_outfold,'lsoas11_museum17_stats.xlsx'))
rm(mus_gss,df,df1)

# ------------------------------------------
# Deprivation: get museum stats
# ------------------------------------------
names(mus_depriv_sdf)

dir.create(paste0(depriv_outfold,'COUNTRY'))

# get numeric stats
num_df = mus_depriv_sdf[, c(depriv_cols,'country')]@data
#sum_df = FUN_get_numeric_df_summary(num_df, normStats = T)
#write_xlsx(sum_df, paste0(depriv_outfold,'mus2017_depriv_lsoa2015-decile_as_num--stats.xlsx'))
for(var in names(num_df)[2:ncol(num_df)]){
  FUN_twoVarStats(num_df, var, "country", paste0(depriv_outfold,'COUNTRY/mus2017_depriv_'))
  rm(var)
}

# plot lines
mnum_df = melt(num_df,id.vars = "country")
head(mnum_df)
mnum_df$value = as.numeric(mnum_df$value)
fn = paste0(depriv_outfold,'COUNTRY/mus2017_depriv_LSOA_2015-1var_num-boxplot.pdf')
p = ggplot(data=mnum_df, aes(x=variable, y=value, fill=variable)) + facet_grid(. ~ country) +
      geom_boxplot() + xlab("Deprivation index") + ylab('Deprivation decile (1=high, 10=low)')+
      scale_y_reverse( lim=c(10,0.5)) +
      ggtitle("Museums located in LSOAs by country with all deprivation indices (deciles)",
              subtitle = paste0("File: ",fn)) +
      theme_light()  + theme(axis.text.x = element_text(angle = 65, hjust = 1))
ggsave(fn,p,width = 20,height = 6)

rm(sum_df,p,fn,mnum_df)

# get factor stats and boxplots
for (col in depriv_cols){
  #if (col!="income") next() # debug
  vals = mus_depriv_sdf@data[,col]
  #print(vals)
  print(col)
  # create folder
  subfolder = paste0(depriv_outfold, '/', gsub('_fac','',col),'/')
  dir.create(subfolder, showWarnings = F)
  df = p_summary_list( format_depr_index(vals), paste0("museums-DEPRIV_LSOA-",col))
  write_xlsx(df, paste0(subfolder,'mus2017_depriv15_LSOA-1var_fac-',col,'.xlsx'))
  rm(df,vals)
  # compare two variables
  for (a in c("governance","governance_simpl","size","accreditation",
              "subject_matter_simpl_aggr")){
    fout = paste0( subfolder, 'mus2017_depriv15_LSOA-2var_fac-',col,"-",a )
    # gen categorical heatmap, filter NULL values out
    df = subset( mus_depriv_sdf@data, !is.na(mus_depriv_sdf@data$UNIT_GSS ))
    df[,col] = format_depr_index(df[,col]) # format to make sure that deciles are ordered
    FUN_gen_freq_matrix( df, a, col, fout )
    rm(df)
    # gen numeric boxplots
    #num_col = gsub('_fac','',col)
    #print(paste("boxplots",a,col,num_col))
    
    stopifnot(a!=col)
    
    # prep data for boxplot
    meltdf = melt( mus_depriv_sdf@data[,c("COUNTRY",a,col)], measure.vars = c(col) )
    #print(summary(meltdf))
    meltdf = subset(meltdf, !is.na(meltdf$COUNTRY))
    meltdf$COUNTRY = as.factor(as.character(meltdf$COUNTRY))
    meltdf$value = as.numeric(meltdf$value)
    meltdf$variable = meltdf[,c(a)]
    
    fn = paste0(subfolder,'mus2017_depriv15_LSOA-country_2var_num-',col,'-',a,'--boxplot.pdf')
    p = ggplot(data = meltdf, aes(x=variable, y=value, color=variable)) + facet_grid(. ~ COUNTRY) +
      geom_boxplot() + xlab(a) + ylab('Deprivation decile (1=high, 10=low)')+
      scale_y_reverse( lim=c(10,.5)) +
      ggtitle(paste0("Museums in LSOAs with depriv. index ",col," vs ",a),
              subtitle = paste0("File: ",fn))+
      theme_light() + 
      theme(axis.text.x = element_text(angle = 60, hjust = 1), legend.position="none")
    ggsave(fn,p,width=10)
    rm(fn,p,num_col,meltdf)
  }
  rm(subfolder)
}
rm(num_df)

# ------------------------------------
# Deprivation maps 
# ------------------------------------
# load simplified LSOA
#lsoa = load_uk_dataset("uk_lsoa_2011-simp0005.rds")
countries = load_uk_dataset("uk_countries_and_eng_regions_2011-simp0001.rds")

# print deprivation of museums as dots on LSOAs
mus_depriv_sdf$combined_idx_dec_num = as.numeric(mus_depriv_sdf$combined_idx_dec)
p = tmap::tm_shape(countries) + tm_borders(col='lightgray', lwd = 0.2) + 
  #tm_text("GSS"size = .1) +
  tmap::tm_shape(mus_depriv_sdf) +
  tm_dots("combined_idx_dec", size = .01, alpha=.5, style='fixed', n=5, palette="RdYlGn")
tmap::save_tmap(p, paste0( depriv_outfold, 'museums2017_depriv_deciles_LSOA_map_UK.pdf' ))
rm(p)
rm(countries)

# London map
lads = load_uk_dataset("uk_local_auth_2011-simp005.rds")
sdf_London = lads[ grepl('E090', lads$GSS), ]
#print( nrow(sdf_London) )
stopifnot(nrow(sdf_London)>0)
p = tmap::tm_shape(sdf_London) + tm_borders(col='lightgray', lwd = 1) + 
  #tm_text("GSS",size = .1) +
  tmap::tm_shape( subset(mus_depriv_sdf, mus_depriv_sdf$region_gss=='E12000007') ) +
  tm_dots("combined_idx_dec", size = .1, alpha=.5, style='fixed', n=5, palette="RdYlGn")
tmap::save_tmap(p, paste0( depriv_outfold, 'museums2017_depriv_deciles_LSOA_map_london.pdf' ))
rm(p)

rm(depriv15sdf,mus_depriv_sdf,sdf_London,lads,depriv_cols)
```

# Models

Notes from Chris Brunson

- seriation R package to observe clusters 
https://cran.r-project.org/web/packages/seriation/index.html
- To study interactions between two variables: Chi square tests on 2-3 variables

- To study distribution of museums: Poisson regression, good for sparse events, starting with LADs
  - GWR would need to be done with a large radius
  - AIC can be used to see how good a model is and choose input variables/scale of OAC/urban rural
  - Ripley K function for distribution of museum subjects
- Accessibility: definitely include street network. Distance matrix can be calcualted in ArcMap and then used as input in R.
- Motorways: case study so that temporal data is not too long/difficult to collect.
- Adrian wall is an interesting case study.

## Var distributions

```{r museum_sp_distrib, eval=T}

TODO

mdf = merge( oaclad2011sdf, museum_sp_stats_lad_df, by="GSS" )

# note that some museums are missing because they have no spatial unit (e.g., isle of man)
stopifnot(nrow(mdf)==nrow(oaclad2011sdf))

# prep data
df = oaclad2011sdf@data
census_lad_df = df[,names(df)[c(1,seq(12,ncol(df)))]]
row.names(census_lad_df) = df$GSS
rm(df)
census_lad_mdf <- melt( census_lad_df, id.vars = "GSS" )
#View(census_lad_df)

# HISTOGRAM of all variables
census_lad_hist <- ggplot(census_lad_mdf, aes(x=value)) + geom_histogram(bins=30) +
                    facet_wrap(~variable, scales = 'free')
ggsave( paste0(OUTFOLD,"census_lad_hist.pdf"), census_lad_hist, width = 25, height = 20)
rm(census_lad_hist)

# STATS tests
census_lad_stats <- stat.desc(census_lad_df, norm=TRUE)
census_lad_stats_df = round(as.data.frame(t(census_lad_stats[c("normtest.p","normtest.W","nbr.val","nbr.na","skewness","skew.2SE","kurtosis","kurt.2SE"),])),3)
census_lad_stats_df = cbind( row.names(census_lad_stats_df), census_lad_stats_df )
write_xlsx(census_lad_stats_df, paste0(OUTFOLD,"census_lad_stats.xlsx"))
rm(census_lad_stats,census_lad_stats_df)

rm(mdf,census_lad_mdf,df)

# HISTOGRAM of museum vars
museum_sp_stats_lad_mdf <- melt( museum_sp_stats_lad_df, id.vars = "GSS" )
mus_lad_hist <- ggplot(museum_sp_stats_lad_mdf, aes(x=value)) + geom_histogram(bins=20) +
                    facet_wrap(~variable, scales = 'free')
ggsave( paste0(OUTFOLD,"museum_lad_hist.pdf"), mus_lad_hist, width = 25, height = 20)
rm(mus_lad_hist)
rm(museum_sp_stats_lad_mdf)

# Museum STATS tests
museum_sp_stats_lad_stats <- stat.desc(museum_sp_stats_lad_df, norm=TRUE)
museum_sp_stats_lad_stats_df = round(as.data.frame(t(museum_sp_stats_lad_stats[c("normtest.p","normtest.W","nbr.val","nbr.na","skewness","skew.2SE","kurtosis","kurt.2SE"),])),3)
museum_sp_stats_lad_stats_df = cbind( row.names(museum_sp_stats_lad_stats_df), museum_sp_stats_lad_stats_df )
write_xlsx(museum_sp_stats_lad_stats_df, paste0(OUTFOLD,"museum_lad_stats.xlsx"))
rm(museum_sp_stats_lad_stats,museum_sp_stats_lad_stats_df)
```

## Var normalisation

```{r museum_sp_normal, eval=T}

all_vars = merge( museum_sp_stats_lad_df, census_lad_df, by="GSS" )
# keep relevant variables
names(all_vars)
work_vars = names(all_vars)[ grepl("*.work*.",names(all_vars)) ]
live_vars = names(all_vars)[ grepl("*.live*.",names(all_vars)) ]
decade_vars = names(all_vars)[ grepl("*.mlad_19*.",names(all_vars)) ]
age_vars = names(all_vars)[ grepl("*persons_aged*.",names(all_vars)) & nchar(names(all_vars)) < 23 ]
sel_vars = all_vars[,
    unique(c("GSS","mlad_all",decade_vars,age_vars,
      "mlad_independent","mlad_state","mlad_hybrid","mlad_large","mlad_medium","mlad_unknown_sz",
      "mlad_local_histories","mlad_buildings","mlad_war_and_conflict","mlad_transport","mlad_arts",
      "number_of_persons_per_hectare",
      "pc_persons_who_are_white", "pc_persons_who_are_asian_asian_british_indian_pakistani_bangladeshi",
      "pc_persons_who_are_asian_asian_british_chinese_and_other",
      "pc_persons_who_are_black_african_caribbean_black_british",
      "pc_persons_who_are_arab_or_are_from_another_ethnic_group",
      "pc_persons_whose_country_of_birth_is_the_uk_or_ireland",
      "pc_households_with_full_time_students",
      "pc_households_who_are_social_renting",
      "pc_persons_aged_16_whose_highest_level_of_qualification_is_level_4_qualifications_and_above",
      "pc_persons_aged_16_whose_highest_level_of_qualification_is_level_3_qualifications",
      "pc_persons_aged_16_74_who_are_unemployed",
      work_vars, live_vars))
    ]

# print diagnostics
sel_vars_m <- melt( sel_vars, id.vars = "GSS" )
sel_vars_hist <- ggplot(sel_vars_m, aes(x=value)) + geom_histogram(bins=20) +
                    facet_wrap(~variable, scales = 'free',ncol = 4)
ggsave( paste0(OUTFOLD,"museum_census_lad_hist.pdf"), sel_vars_hist, width = 15, height = 40)
rm(sel_vars_hist,sel_vars_m)

sel_vars_stats <- stat.desc(sel_vars, norm=TRUE)
sel_vars_stats_df = round(as.data.frame(t(sel_vars_stats[c("normtest.p","normtest.W","nbr.val","nbr.na","skewness","skew.2SE","kurtosis","kurt.2SE"),])),3)
sel_vars_stats_df = cbind( row.names(sel_vars_stats_df), sel_vars_stats_df )
write_xlsx(sel_vars_stats_df, paste0(OUTFOLD,"museum_census_lad_stats.xlsx"))
rm(sel_vars_stats,sel_vars_stats_df)
names(sel_vars)
asinh_norm_vars = c( names(sel_vars)[ grepl("mlad",names(sel_vars)) ],
    names(sel_vars)[ grepl(".*persons_who_are.*",names(sel_vars))],
    "number_of_persons_per_hectare",
    "pc_persons_whose_country_of_birth_is_the_uk_or_ireland",
    "pc_households_with_full_time_students",
    "pc_employed_persons_aged_16_74_who_work_in_the_agriculture_forestry_or_fishing_industries",
    "pc_persons_living_in_a_communal_establishment",
    "pc_households_who_live_in_a_flat",
    "pc_households_who_live_in_a_caravan_or_other_mobile_or_temporary_structure"
  )

not_to_norm_vars = setdiff( names(sel_vars), asinh_norm_vars )

norm_vars = sel_vars #[, not_to_norm_vars]

for (v in asinh_norm_vars){
  norm_v = paste0(v,"_asinh")
  #norm_vars[,norm_v] = asinh(sel_vars[,v])
}

# plot normalised vars
sel_vars_m <- melt( norm_vars, id.vars = "GSS" )
sel_vars_hist <- ggplot(sel_vars_m, aes(x=value)) + geom_histogram(bins=20) +
                    facet_wrap(~variable, scales = 'free',ncol = 4)
ggsave( paste0(OUTFOLD,"museum_census_lad_norm_hist.pdf"), sel_vars_hist, width = 15, height = 40)
rm(sel_vars_hist, sel_vars_m)

```

## Correlations

```{r museum_sp_corrs, eval=T}

get_all_corrs <- function(df, varsA, varsB ){
  corrs_df=data.frame()
  for(a in varsA){
  for(b in varsB){
      #print(paste(m,a,b))
      if(a==b) next

      vars=paste(sort(c(a,b)),collapse = ' ')
      row = data.frame( VAR_A = a, VAR_B = b, VARS=vars )

      c = cor.test( df[,a], df[,b], method="spearman", exact = F )
      row$SPEAR_COR = round(c$estimate,2)
      row$SPEAR_PVAL = round(c$p.value,5)
      c = cor.test( df[,a], df[,b], method="kendall", exact = F )
      row$KEND_COR = round(c$estimate,2)
      row$KEND_PVAL = round(c$p.value,5)

      if (any(!vars %in% corrs_df$VARS))
        corrs_df = rbind(corrs_df,row)
  }}
  rm(row,c)
  return(corrs_df)
}

#View(norm_vars)
# get all correlations
vars_A = names(norm_vars)[ grepl("mlad",names(norm_vars)) ]
vars_B = setdiff( names(norm_vars), vars_A )
vars_B = setdiff( vars_B, "GSS" )

corrs_df = get_all_corrs(norm_vars, vars_A, vars_B)
write_xlsx(corrs_df, paste0(OUTFOLD,"museum_census_lad_corrs.xlsx"))

corrs_df = get_all_corrs(norm_vars, vars_A, vars_A)
write_xlsx(corrs_df, paste0(OUTFOLD,"museum_lad_corrs.xlsx"))

corrs_df = get_all_corrs(norm_vars, vars_B, vars_B)
write_xlsx(corrs_df, paste0(OUTFOLD,"census_lad_corrs.xlsx"))

rm(all_vars,sel_vars,corrs_df)

# TODO: use kendall because of the ties!

# TODO: set up regressions

```

# Audience Agency 2020

match between Audience Agency museums and MM museums.
Results in 
https://docs.google.com/spreadsheets/d/15YvpMUjxmNRiZ52ratbmR64wyfIFe7L2yDJQ5u4Z2nU/edit?usp=sharing

## Prep data

```{r}

outfolder = "../tmp/"

fn = "../datasets/museums/input/maindata/mm_input_maindatasheet_09_May_2018.csv"
headers = read.csv(db_fn, skip = 0, sep = "$", header = F, nrows = 1, as.is = T)
full_df = read.csv(db_fn, sep = "$", skip = 5, header = F)
colnames(full_df)=headers
rm(headers)
#View(full_df)
is_unique(full_df$project_id)
mdf = full_df[,c("project_id","Name of museum")]
names(mdf) = c("id","name")
rm(full_df)
#mdf = head(mdf)

aa_df = read.csv("../datasets/audience_agency/aa_2016_2019.csv", encoding = "UTF8")
names(aa_df)
#aa_df = aa_df[sample(nrow(aa_df), 10), ]  # DEBUG
aanames = aa_df[,c("ID")]
#View(aa_df)

sim_methods = c("jw", "lv" ,"qgram") #, "dl", "hamming", "lcs", "qgram", "cosine", "jaccard", "jw", "soundex") "hamming",

# match museum names
all_sim_df = lapply(sim_methods, function(sim_method){
  sim_df = lapply(as.character(aanames), function(name){
    sims = stringsim(tolower(name), as.character(tolower(mdf$name)), method=sim_method)
    df = data.frame(AA_NAME=name, MM_NAME=mdf$name, MM_ID=mdf$id, SIM=round(sims,2))
    df$PERFECT_MATCH = (max(df$SIM) == 1)
    df$METHOD = sim_method
    df$RANK = rank(-df$SIM)
    if (max(sims) == 1.0){
      df = subset(df, df$SIM >= 1)
    }
    return(df)
  })
  return(rbindlist(sim_df))
})

all_sim_df = rbindlist(all_sim_df)
all_sim_df = subset(all_sim_df, all_sim_df$RANK <= 3)
all_sim_df$HIGH_SIM = all_sim_df$SIM >= .9

write_csv(all_sim_df, "../tmp/audience_agency_sim_table.csv")
View(all_sim_df)

rm(mdf)
```

## Analysis & viz

```{r}

outfolder = "../plots/audience_agency/"

df = read_csv("../datasets/audience_agency/audience_agency_sim_table-match-2020-05-26.csv")
summary(df)
View(df)
View(museums_bg@data)
length(unique(df$AA_NAME))
cdf = subset(df, df$CORRECT_MATCH == TRUE | df$PERFECT_MATCH == TRUE)
length(unique(cdf$AA_NAME))

print("FOUND")
print(unique(cdf$AA_NAME))

fcd = subset(df, !(df$AA_NAME %in% cdf$AA_NAME))
print("MISSING")
print(length(unique(fcd$AA_NAME)))
cat(paste(unique(fcd$AA_NAME),collapse = "\n"))

missing_n = 31
# 11% not found (25 out of 239)

#View(fcd)
rm(fcd)

# summarise matched museums
head(cdf)
df = unique(cdf[,c("AA_NAME", "MM_NAME", "MM_ID")])
df$MM_ID = trimws(df$MM_ID)
nrow(df)
length(unique(df$MM_ID))
View(df)

msdf = museums_bg@data[museums_bg@data$project_id %in% df$MM_ID, ]
nrow(msdf)

missing_df = df[!(df$MM_ID %in% msdf$project_id), ]
#View(missing_df)
nrow(msdf)

for (v in c("size","subject_matter_simpl","region_name","subject_matter",
            "accreditation","governance","lad16_name")){
  df = as.data.frame(FUN_count_groups_by_vars(msdf, v))
  # add unknown cases
  df[,1] = as.character(df[,1])
  df[nrow(df) + 1,] = list("_unmapped_aa_", missing_n)
  df$pc = round(df$n / sum(df$n)*100, 1)
  df = sort_df(df, "pc", asc = F )
  write_xlsx(df, paste0(outfolder,paste0("aa_",v,".xlsx")))
}

summary(msdf)

```

